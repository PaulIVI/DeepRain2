{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.loadset import getDataSet\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "import os\n",
    "from trainer import Trainer\n",
    "try:\n",
    "    from Utils.connection_cfg import *\n",
    "except Exception as e:\n",
    "    PSWD = None\n",
    "    USRN = None\n",
    "    \n",
    "from Utils.Data import dataWrapper\n",
    "from Utils.transform import Binarize\n",
    "\n",
    "dimension = (64,64)\n",
    "channels = 5\n",
    "optimizer = Adam( lr = 1e-5 )\n",
    "tfd = tfp.distributions\n",
    "\n",
    "def NLL(y_true, y_hat):\n",
    "    return -y_hat.log_prob(y_true)\n",
    "\n",
    "def mixd(output):\n",
    "    rate = tf.math.exp(output[0,:,:,0]) #A \n",
    "    s = tf.math.sigmoid(output[0,:,:,1])\n",
    "    components = [tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
    "     tfd.Poisson(rate=rate) #F \n",
    "     ]\n",
    "    mixture = tfd.Mixture(\n",
    "          cat=tfd.Categorical(probs=tf.stack([1-s, s],axis=-1)),#D\n",
    "          components=components)\n",
    "    \n",
    "    return mixture\n",
    "    \n",
    "def testnetBernoulli(input_shape,\n",
    "           n_predictions=1,\n",
    "           simpleclassification=None,\n",
    "           flatten_output=False,\n",
    "           activation_hidden=\"relu\",\n",
    "           activation_output=\"relu\"):\n",
    "\n",
    "\n",
    "    inputs = Input(shape=input_shape) \n",
    "\n",
    "    conv01 = Conv2D(10, kernel_size=(3, 3), padding=\"same\")(inputs)       # 10 x 64x64\n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            # 10 x 32x32\n",
    "\n",
    "\n",
    "    conv02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  # 20 x 32x32\n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            # 20 x 16x16\n",
    "\n",
    "\n",
    "    conv03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  # 20 x 16x16\n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            # 20 x 8x8\n",
    "\n",
    "\n",
    "    conv04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  # 20 x 8x8\n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            # 20 x 4x4\n",
    "\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = UpSampling2D((2, 2))(conv04_pool)    # 20 x 8x8\n",
    "    up04 = concatenate([conv04, up04], axis=3)  # 20+20 x 8x8\n",
    "\n",
    "\n",
    "    up03 = UpSampling2D((2, 2))(up04)           # 40 x 16x16\n",
    "    up03 = concatenate([conv03, up03], axis=3)  # 20+40 x 16x16\n",
    "\n",
    "\n",
    "    up02 = UpSampling2D((2, 2))(up03)           # 60 x 32x32\n",
    "    up02 = concatenate([conv02, up02], axis=3)  # 20+60 x 32x32\n",
    "\n",
    "\n",
    "    up01 = UpSampling2D((2, 2))(up02)           # 80 x 64x64\n",
    "    up01 = concatenate([conv01, up01], axis=3)  # 10+80 x 64x64\n",
    "\n",
    "\n",
    "    output = Conv2D(1, (1, 1), activation=tf.exp)(up01)  # 1 x 64x64\n",
    "    #output = tfkl.Flatten()(output)\n",
    "    output = tfpl.IndependentBernoulli((1), tfd.Bernoulli.logits)(output)\n",
    "    #outpus = tfd.Independent(tfd.Poisson(),name=\"image\")(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "def provideData(flatten=False,dimension=dimension,batch_size=10,transform=None,preTransformation=None):\n",
    "\n",
    "    getDataSet(DatasetFolder,year=[2017],username=USRN,pswd=PSWD)\n",
    "    train,test = dataWrapper(PathToData,\n",
    "                            dimension=dimension,\n",
    "                            channels=channels,\n",
    "                            batch_size=batch_size,\n",
    "                            overwritecsv=True,\n",
    "                            flatten=flatten,\n",
    "                            onlyUseYears=[2017],\n",
    "                            transform=transform,\n",
    "                            preTransformation=preTransformation)\n",
    "    \n",
    "    return train,test\n",
    "DatasetFolder = \"./Data/RAW\"\n",
    "PathToData = os.path.join(DatasetFolder,\"MonthPNGData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFound Year \u001b[0m:  2017 => won't download this year again... please check for consistency\n",
      "\u001b[32mFinished Loading Dataset\n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train, test = provideData(flatten=False,dimension=dimension,batch_size=1,transform=[Binarize()],preTransformation=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded file]  ./model_data/testnetBernoulli_function/testnetBernoulli_function64x64x5.h5\n",
      "100\n",
      "[Loaded file]  ./model_data/testnetBernoulli_function/testnetBernoulli_function64x64x5history.json\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 64, 64, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 10)   460         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 10)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 32, 32, 10)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 20)   1820        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 20)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 16, 16, 20)   0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 20)   3620        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 20)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 8, 8, 20)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 20)     3620        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 20)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 4, 4, 20)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 8, 8, 20)     0           max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 40)     0           activation_19[0][0]              \n",
      "                                                                 up_sampling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 16, 16, 40)   0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 60)   0           activation_18[0][0]              \n",
      "                                                                 up_sampling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 32, 32, 60)   0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 80)   0           activation_17[0][0]              \n",
      "                                                                 up_sampling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 64, 64, 80)   0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 64, 64, 90)   0           activation_16[0][0]              \n",
      "                                                                 up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 1)    91          concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "independent_bernoulli_4 (Indepe ((None, 64, 64, 1),  0           conv2d_24[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,611\n",
      "Trainable params: 9,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "len train,val 10 10\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 101/2100\n",
      "10/10 [==============================] - 1s 80ms/step - loss: 60.0720 - mse: 0.2187 - mae: 0.4640 - val_loss: 49.7022 - val_mse: 0.1618 - val_mae: 0.3094\n",
      "Epoch 102/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 58.7778 - mse: 0.1900 - mae: 0.4313 - val_loss: 49.0321 - val_mse: 0.1582 - val_mae: 0.2925\n",
      "Epoch 103/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 57.4912 - mse: 0.1630 - mae: 0.3978 - val_loss: 48.4624 - val_mse: 0.1538 - val_mae: 0.2760\n",
      "Epoch 104/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 56.4434 - mse: 0.1429 - mae: 0.3708 - val_loss: 47.9678 - val_mse: 0.1514 - val_mae: 0.2630\n",
      "Epoch 105/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 55.4662 - mse: 0.1252 - mae: 0.3448 - val_loss: 47.6294 - val_mse: 0.1506 - val_mae: 0.2533\n",
      "Epoch 106/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 54.7007 - mse: 0.1122 - mae: 0.3244 - val_loss: 47.2840 - val_mse: 0.1498 - val_mae: 0.2438\n",
      "Epoch 107/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 53.9900 - mse: 0.1006 - mae: 0.3048 - val_loss: 47.0418 - val_mse: 0.1498 - val_mae: 0.2373\n",
      "Epoch 108/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 53.3053 - mse: 0.0911 - mae: 0.2870 - val_loss: 46.7796 - val_mse: 0.1500 - val_mae: 0.2303\n",
      "Epoch 109/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 52.7622 - mse: 0.0831 - mae: 0.2717 - val_loss: 46.5971 - val_mse: 0.1489 - val_mae: 0.2245\n",
      "Epoch 110/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 52.2296 - mse: 0.0761 - mae: 0.2570 - val_loss: 46.4095 - val_mse: 0.1492 - val_mae: 0.2190\n",
      "Epoch 111/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 51.8249 - mse: 0.0706 - mae: 0.2455 - val_loss: 46.2437 - val_mse: 0.1498 - val_mae: 0.2149\n",
      "Epoch 112/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 51.3576 - mse: 0.0654 - mae: 0.2328 - val_loss: 46.1305 - val_mse: 0.1500 - val_mae: 0.2112\n",
      "Epoch 113/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 50.9524 - mse: 0.0613 - mae: 0.2219 - val_loss: 45.9870 - val_mse: 0.1494 - val_mae: 0.2069\n",
      "Epoch 114/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 50.6022 - mse: 0.0571 - mae: 0.2115 - val_loss: 45.8831 - val_mse: 0.1511 - val_mae: 0.2048\n",
      "Epoch 115/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 50.2748 - mse: 0.0539 - mae: 0.2022 - val_loss: 45.7822 - val_mse: 0.1499 - val_mae: 0.2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 49.9715 - mse: 0.0510 - mae: 0.1936 - val_loss: 45.6781 - val_mse: 0.1511 - val_mae: 0.1986\n",
      "Epoch 117/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 49.6899 - mse: 0.0484 - mae: 0.1856 - val_loss: 45.6148 - val_mse: 0.1513 - val_mae: 0.1963\n",
      "Epoch 118/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 49.4214 - mse: 0.0461 - mae: 0.1778 - val_loss: 45.5190 - val_mse: 0.1513 - val_mae: 0.1938\n",
      "Epoch 119/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 49.1704 - mse: 0.0440 - mae: 0.1705 - val_loss: 45.4592 - val_mse: 0.1517 - val_mae: 0.1919\n",
      "Epoch 120/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.9449 - mse: 0.0425 - mae: 0.1644 - val_loss: 45.4076 - val_mse: 0.1517 - val_mae: 0.1900\n",
      "Epoch 121/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 48.7465 - mse: 0.0406 - mae: 0.1582 - val_loss: 45.3344 - val_mse: 0.1524 - val_mae: 0.1883\n",
      "Epoch 122/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.5376 - mse: 0.0393 - mae: 0.1523 - val_loss: 45.2850 - val_mse: 0.1523 - val_mae: 0.1866\n",
      "Epoch 123/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.3516 - mse: 0.0380 - mae: 0.1469 - val_loss: 45.2283 - val_mse: 0.1534 - val_mae: 0.1856\n",
      "Epoch 124/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.1546 - mse: 0.0367 - mae: 0.1410 - val_loss: 45.1923 - val_mse: 0.1524 - val_mae: 0.1835\n",
      "Epoch 125/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.0072 - mse: 0.0360 - mae: 0.1369 - val_loss: 45.1427 - val_mse: 0.1534 - val_mae: 0.1826\n",
      "Epoch 126/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 47.8378 - mse: 0.0349 - mae: 0.1319 - val_loss: 45.1060 - val_mse: 0.1536 - val_mae: 0.1817\n",
      "Epoch 127/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.7277 - mse: 0.0340 - mae: 0.1283 - val_loss: 45.0692 - val_mse: 0.1533 - val_mae: 0.1799\n",
      "Epoch 128/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 47.5611 - mse: 0.0333 - mae: 0.1235 - val_loss: 45.0342 - val_mse: 0.1538 - val_mae: 0.1793\n",
      "Epoch 129/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.4352 - mse: 0.0326 - mae: 0.1198 - val_loss: 45.0001 - val_mse: 0.1541 - val_mae: 0.1783\n",
      "Epoch 130/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 47.3122 - mse: 0.0322 - mae: 0.1164 - val_loss: 44.9745 - val_mse: 0.1542 - val_mae: 0.1774\n",
      "Epoch 131/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 47.1987 - mse: 0.0317 - mae: 0.1131 - val_loss: 44.9415 - val_mse: 0.1551 - val_mae: 0.1771\n",
      "Epoch 132/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.0905 - mse: 0.0308 - mae: 0.1094 - val_loss: 44.9201 - val_mse: 0.1542 - val_mae: 0.1755\n",
      "Epoch 133/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.9807 - mse: 0.0307 - mae: 0.1064 - val_loss: 44.8955 - val_mse: 0.1544 - val_mae: 0.1749\n",
      "Epoch 134/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 46.8957 - mse: 0.0302 - mae: 0.1038 - val_loss: 44.8697 - val_mse: 0.1552 - val_mae: 0.1745\n",
      "Epoch 135/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.7896 - mse: 0.0300 - mae: 0.1008 - val_loss: 44.8496 - val_mse: 0.1549 - val_mae: 0.1736\n",
      "Epoch 136/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.6967 - mse: 0.0294 - mae: 0.0977 - val_loss: 44.8292 - val_mse: 0.1552 - val_mae: 0.1731\n",
      "Epoch 137/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 46.6197 - mse: 0.0293 - mae: 0.0956 - val_loss: 44.8112 - val_mse: 0.1552 - val_mae: 0.1725\n",
      "Epoch 138/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 46.5525 - mse: 0.0287 - mae: 0.0932 - val_loss: 44.7922 - val_mse: 0.1554 - val_mae: 0.1720\n",
      "Epoch 139/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 46.4453 - mse: 0.0291 - mae: 0.0907 - val_loss: 44.7741 - val_mse: 0.1558 - val_mae: 0.1716\n",
      "Epoch 140/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 46.3895 - mse: 0.0285 - mae: 0.0887 - val_loss: 44.7597 - val_mse: 0.1557 - val_mae: 0.1712\n",
      "Epoch 141/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.3266 - mse: 0.0283 - mae: 0.0868 - val_loss: 44.7419 - val_mse: 0.1553 - val_mae: 0.1700\n",
      "Epoch 142/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 46.2478 - mse: 0.0281 - mae: 0.0844 - val_loss: 44.7317 - val_mse: 0.1559 - val_mae: 0.1702\n",
      "Epoch 143/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.1835 - mse: 0.0282 - mae: 0.0827 - val_loss: 44.7158 - val_mse: 0.1560 - val_mae: 0.1698\n",
      "Epoch 144/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.1529 - mse: 0.0272 - mae: 0.0808 - val_loss: 44.7005 - val_mse: 0.1566 - val_mae: 0.1697\n",
      "Epoch 145/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 46.0602 - mse: 0.0279 - mae: 0.0790 - val_loss: 44.6927 - val_mse: 0.1559 - val_mae: 0.1689\n",
      "Epoch 146/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.0264 - mse: 0.0277 - mae: 0.0779 - val_loss: 44.6773 - val_mse: 0.1558 - val_mae: 0.1681\n",
      "Epoch 147/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.9624 - mse: 0.0273 - mae: 0.0757 - val_loss: 44.6695 - val_mse: 0.1568 - val_mae: 0.1688\n",
      "Epoch 148/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.9166 - mse: 0.0272 - mae: 0.0743 - val_loss: 44.6559 - val_mse: 0.1567 - val_mae: 0.1680\n",
      "Epoch 149/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.8612 - mse: 0.0274 - mae: 0.0729 - val_loss: 44.6473 - val_mse: 0.1565 - val_mae: 0.1676\n",
      "Epoch 150/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.8205 - mse: 0.0269 - mae: 0.0712 - val_loss: 44.6356 - val_mse: 0.1563 - val_mae: 0.1671\n",
      "Epoch 151/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.7703 - mse: 0.0273 - mae: 0.0702 - val_loss: 44.6306 - val_mse: 0.1569 - val_mae: 0.1673\n",
      "Epoch 152/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.7516 - mse: 0.0263 - mae: 0.0686 - val_loss: 44.6198 - val_mse: 0.1560 - val_mae: 0.1661\n",
      "Epoch 153/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.6893 - mse: 0.0273 - mae: 0.0679 - val_loss: 44.6129 - val_mse: 0.1569 - val_mae: 0.1667\n",
      "Epoch 154/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.6523 - mse: 0.0267 - mae: 0.0662 - val_loss: 44.6037 - val_mse: 0.1568 - val_mae: 0.1662\n",
      "Epoch 155/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 45.6178 - mse: 0.0269 - mae: 0.0654 - val_loss: 44.5947 - val_mse: 0.1569 - val_mae: 0.1660\n",
      "Epoch 156/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 45.5679 - mse: 0.0269 - mae: 0.0640 - val_loss: 44.5883 - val_mse: 0.1576 - val_mae: 0.1664\n",
      "Epoch 157/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.5458 - mse: 0.0266 - mae: 0.0631 - val_loss: 44.5831 - val_mse: 0.1566 - val_mae: 0.1652\n",
      "Epoch 158/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.5178 - mse: 0.0263 - mae: 0.0619 - val_loss: 44.5741 - val_mse: 0.1575 - val_mae: 0.1658\n",
      "Epoch 159/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 45.4809 - mse: 0.0264 - mae: 0.0609 - val_loss: 44.5694 - val_mse: 0.1572 - val_mae: 0.1653\n",
      "Epoch 160/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 45.4492 - mse: 0.0267 - mae: 0.0603 - val_loss: 44.5638 - val_mse: 0.1566 - val_mae: 0.1645\n",
      "Epoch 161/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.4239 - mse: 0.0265 - mae: 0.0594 - val_loss: 44.5566 - val_mse: 0.1573 - val_mae: 0.1649\n",
      "Epoch 162/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.3923 - mse: 0.0264 - mae: 0.0583 - val_loss: 44.5517 - val_mse: 0.1575 - val_mae: 0.1650\n",
      "Epoch 163/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.3682 - mse: 0.0261 - mae: 0.0573 - val_loss: 44.5451 - val_mse: 0.1569 - val_mae: 0.1640\n",
      "Epoch 164/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.3293 - mse: 0.0267 - mae: 0.0567 - val_loss: 44.5415 - val_mse: 0.1576 - val_mae: 0.1646\n",
      "Epoch 165/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.3074 - mse: 0.0268 - mae: 0.0562 - val_loss: 44.5362 - val_mse: 0.1577 - val_mae: 0.1645\n",
      "Epoch 166/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 45.2924 - mse: 0.0263 - mae: 0.0552 - val_loss: 44.5309 - val_mse: 0.1572 - val_mae: 0.1638\n",
      "Epoch 167/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.2675 - mse: 0.0262 - mae: 0.0544 - val_loss: 44.5269 - val_mse: 0.1577 - val_mae: 0.1642\n",
      "Epoch 168/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.2383 - mse: 0.0262 - mae: 0.0536 - val_loss: 44.5223 - val_mse: 0.1571 - val_mae: 0.1634\n",
      "Epoch 169/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.2181 - mse: 0.0262 - mae: 0.0530 - val_loss: 44.5171 - val_mse: 0.1582 - val_mae: 0.1642\n",
      "Epoch 170/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.2011 - mse: 0.0265 - mae: 0.0527 - val_loss: 44.5142 - val_mse: 0.1570 - val_mae: 0.1630\n",
      "Epoch 171/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.1783 - mse: 0.0263 - mae: 0.0519 - val_loss: 44.5091 - val_mse: 0.1581 - val_mae: 0.1639\n",
      "Epoch 172/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.1534 - mse: 0.0261 - mae: 0.0509 - val_loss: 44.5070 - val_mse: 0.1573 - val_mae: 0.1630\n",
      "Epoch 173/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.1404 - mse: 0.0263 - mae: 0.0507 - val_loss: 44.5027 - val_mse: 0.1575 - val_mae: 0.1630\n",
      "Epoch 174/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.1189 - mse: 0.0263 - mae: 0.0501 - val_loss: 44.4990 - val_mse: 0.1577 - val_mae: 0.1631\n",
      "Epoch 175/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.1020 - mse: 0.0261 - mae: 0.0494 - val_loss: 44.4952 - val_mse: 0.1578 - val_mae: 0.1630\n",
      "Epoch 176/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.0835 - mse: 0.0263 - mae: 0.0490 - val_loss: 44.4924 - val_mse: 0.1579 - val_mae: 0.1630\n",
      "Epoch 177/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.0610 - mse: 0.0265 - mae: 0.0485 - val_loss: 44.4893 - val_mse: 0.1576 - val_mae: 0.1626\n",
      "Epoch 178/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.0571 - mse: 0.0260 - mae: 0.0478 - val_loss: 44.4844 - val_mse: 0.1582 - val_mae: 0.1630\n",
      "Epoch 179/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.0357 - mse: 0.0261 - mae: 0.0473 - val_loss: 44.4845 - val_mse: 0.1577 - val_mae: 0.1625\n",
      "Epoch 180/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.0199 - mse: 0.0263 - mae: 0.0470 - val_loss: 44.4801 - val_mse: 0.1577 - val_mae: 0.1623\n",
      "Epoch 181/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.0062 - mse: 0.0263 - mae: 0.0466 - val_loss: 44.4777 - val_mse: 0.1582 - val_mae: 0.1628\n",
      "Epoch 182/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9908 - mse: 0.0262 - mae: 0.0460 - val_loss: 44.4737 - val_mse: 0.1581 - val_mae: 0.1624\n",
      "Epoch 183/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9756 - mse: 0.0262 - mae: 0.0455 - val_loss: 44.4731 - val_mse: 0.1574 - val_mae: 0.1617\n",
      "Epoch 184/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9638 - mse: 0.0261 - mae: 0.0451 - val_loss: 44.4696 - val_mse: 0.1580 - val_mae: 0.1622\n",
      "Epoch 185/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9477 - mse: 0.0263 - mae: 0.0448 - val_loss: 44.4669 - val_mse: 0.1581 - val_mae: 0.1622\n",
      "Epoch 186/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.9385 - mse: 0.0261 - mae: 0.0444 - val_loss: 44.4645 - val_mse: 0.1578 - val_mae: 0.1618\n",
      "Epoch 187/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9218 - mse: 0.0266 - mae: 0.0443 - val_loss: 44.4628 - val_mse: 0.1583 - val_mae: 0.1622\n",
      "Epoch 188/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.9197 - mse: 0.0260 - mae: 0.0436 - val_loss: 44.4604 - val_mse: 0.1578 - val_mae: 0.1617\n",
      "Epoch 189/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.8986 - mse: 0.0260 - mae: 0.0430 - val_loss: 44.4569 - val_mse: 0.1584 - val_mae: 0.1621\n",
      "Epoch 190/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.8938 - mse: 0.0264 - mae: 0.0433 - val_loss: 44.4561 - val_mse: 0.1581 - val_mae: 0.1618\n",
      "Epoch 191/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.8796 - mse: 0.0262 - mae: 0.0426 - val_loss: 44.4553 - val_mse: 0.1581 - val_mae: 0.1618\n",
      "Epoch 192/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.8658 - mse: 0.0260 - mae: 0.0420 - val_loss: 44.4520 - val_mse: 0.1577 - val_mae: 0.1613\n",
      "Epoch 193/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.8560 - mse: 0.0266 - mae: 0.0423 - val_loss: 44.4501 - val_mse: 0.1583 - val_mae: 0.1617\n",
      "Epoch 194/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.8487 - mse: 0.0262 - mae: 0.0417 - val_loss: 44.4484 - val_mse: 0.1579 - val_mae: 0.1613\n",
      "Epoch 195/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.8389 - mse: 0.0262 - mae: 0.0414 - val_loss: 44.4461 - val_mse: 0.1587 - val_mae: 0.1620\n",
      "Epoch 196/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.8321 - mse: 0.0261 - mae: 0.0410 - val_loss: 44.4451 - val_mse: 0.1578 - val_mae: 0.1610\n",
      "Epoch 197/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.8220 - mse: 0.0260 - mae: 0.0407 - val_loss: 44.4432 - val_mse: 0.1583 - val_mae: 0.1616\n",
      "Epoch 198/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.8091 - mse: 0.0260 - mae: 0.0403 - val_loss: 44.4406 - val_mse: 0.1583 - val_mae: 0.1614\n",
      "Epoch 199/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.8064 - mse: 0.0259 - mae: 0.0401 - val_loss: 44.4395 - val_mse: 0.1580 - val_mae: 0.1611\n",
      "Epoch 200/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.7898 - mse: 0.0266 - mae: 0.0402 - val_loss: 44.4393 - val_mse: 0.1579 - val_mae: 0.1609\n",
      "Epoch 201/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7855 - mse: 0.0262 - mae: 0.0397 - val_loss: 44.4366 - val_mse: 0.1584 - val_mae: 0.1613\n",
      "Epoch 202/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.7793 - mse: 0.0261 - mae: 0.0394 - val_loss: 44.4354 - val_mse: 0.1580 - val_mae: 0.1609\n",
      "Epoch 203/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.7655 - mse: 0.0266 - mae: 0.0394 - val_loss: 44.4334 - val_mse: 0.1589 - val_mae: 0.1617\n",
      "Epoch 204/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7642 - mse: 0.0261 - mae: 0.0389 - val_loss: 44.4328 - val_mse: 0.1576 - val_mae: 0.1604\n",
      "Epoch 205/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7521 - mse: 0.0263 - mae: 0.0388 - val_loss: 44.4310 - val_mse: 0.1583 - val_mae: 0.1610\n",
      "Epoch 206/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7517 - mse: 0.0260 - mae: 0.0384 - val_loss: 44.4296 - val_mse: 0.1583 - val_mae: 0.1610\n",
      "Epoch 207/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7412 - mse: 0.0257 - mae: 0.0378 - val_loss: 44.4286 - val_mse: 0.1586 - val_mae: 0.1612\n",
      "Epoch 208/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7313 - mse: 0.0267 - mae: 0.0385 - val_loss: 44.4265 - val_mse: 0.1585 - val_mae: 0.1610\n",
      "Epoch 209/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.7248 - mse: 0.0264 - mae: 0.0380 - val_loss: 44.4265 - val_mse: 0.1578 - val_mae: 0.1603\n",
      "Epoch 210/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7212 - mse: 0.0261 - mae: 0.0375 - val_loss: 44.4245 - val_mse: 0.1582 - val_mae: 0.1607\n",
      "Epoch 211/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.7122 - mse: 0.0261 - mae: 0.0373 - val_loss: 44.4236 - val_mse: 0.1590 - val_mae: 0.1614\n",
      "Epoch 212/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.7080 - mse: 0.0263 - mae: 0.0374 - val_loss: 44.4228 - val_mse: 0.1577 - val_mae: 0.1601\n",
      "Epoch 213/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6976 - mse: 0.0265 - mae: 0.0372 - val_loss: 44.4212 - val_mse: 0.1586 - val_mae: 0.1609\n",
      "Epoch 214/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6990 - mse: 0.0260 - mae: 0.0368 - val_loss: 44.4195 - val_mse: 0.1585 - val_mae: 0.1608\n",
      "Epoch 215/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6885 - mse: 0.0261 - mae: 0.0365 - val_loss: 44.4197 - val_mse: 0.1586 - val_mae: 0.1608\n",
      "Epoch 216/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6834 - mse: 0.0263 - mae: 0.0365 - val_loss: 44.4184 - val_mse: 0.1579 - val_mae: 0.1601\n",
      "Epoch 217/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6764 - mse: 0.0263 - mae: 0.0364 - val_loss: 44.4174 - val_mse: 0.1587 - val_mae: 0.1608\n",
      "Epoch 218/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6725 - mse: 0.0263 - mae: 0.0362 - val_loss: 44.4157 - val_mse: 0.1585 - val_mae: 0.1606\n",
      "Epoch 219/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6673 - mse: 0.0265 - mae: 0.0362 - val_loss: 44.4155 - val_mse: 0.1578 - val_mae: 0.1599\n",
      "Epoch 220/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6647 - mse: 0.0257 - mae: 0.0353 - val_loss: 44.4145 - val_mse: 0.1585 - val_mae: 0.1606\n",
      "Epoch 221/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6555 - mse: 0.0266 - mae: 0.0360 - val_loss: 44.4134 - val_mse: 0.1586 - val_mae: 0.1606\n",
      "Epoch 222/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6508 - mse: 0.0265 - mae: 0.0358 - val_loss: 44.4121 - val_mse: 0.1587 - val_mae: 0.1607\n",
      "Epoch 223/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6483 - mse: 0.0260 - mae: 0.0352 - val_loss: 44.4121 - val_mse: 0.1581 - val_mae: 0.1601\n",
      "Epoch 224/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6430 - mse: 0.0264 - mae: 0.0354 - val_loss: 44.4109 - val_mse: 0.1582 - val_mae: 0.1601\n",
      "Epoch 225/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6373 - mse: 0.0262 - mae: 0.0351 - val_loss: 44.4098 - val_mse: 0.1585 - val_mae: 0.1604\n",
      "Epoch 226/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6320 - mse: 0.0263 - mae: 0.0349 - val_loss: 44.4091 - val_mse: 0.1590 - val_mae: 0.1608\n",
      "Epoch 227/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6292 - mse: 0.0262 - mae: 0.0348 - val_loss: 44.4080 - val_mse: 0.1583 - val_mae: 0.1601\n",
      "Epoch 228/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6254 - mse: 0.0264 - mae: 0.0348 - val_loss: 44.4082 - val_mse: 0.1582 - val_mae: 0.1600\n",
      "Epoch 229/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6191 - mse: 0.0263 - mae: 0.0345 - val_loss: 44.4065 - val_mse: 0.1589 - val_mae: 0.1606\n",
      "Epoch 230/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6178 - mse: 0.0264 - mae: 0.0346 - val_loss: 44.4066 - val_mse: 0.1583 - val_mae: 0.1601\n",
      "Epoch 231/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.6117 - mse: 0.0261 - mae: 0.0342 - val_loss: 44.4048 - val_mse: 0.1585 - val_mae: 0.1601\n",
      "Epoch 232/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6074 - mse: 0.0263 - mae: 0.0342 - val_loss: 44.4051 - val_mse: 0.1581 - val_mae: 0.1597\n",
      "Epoch 233/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.6056 - mse: 0.0264 - mae: 0.0343 - val_loss: 44.4042 - val_mse: 0.1590 - val_mae: 0.1606\n",
      "Epoch 234/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5976 - mse: 0.0265 - mae: 0.0341 - val_loss: 44.4032 - val_mse: 0.1582 - val_mae: 0.1598\n",
      "Epoch 235/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5981 - mse: 0.0259 - mae: 0.0334 - val_loss: 44.4027 - val_mse: 0.1585 - val_mae: 0.1601\n",
      "Epoch 236/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5954 - mse: 0.0260 - mae: 0.0335 - val_loss: 44.4021 - val_mse: 0.1584 - val_mae: 0.1600\n",
      "Epoch 237/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5873 - mse: 0.0266 - mae: 0.0338 - val_loss: 44.4014 - val_mse: 0.1585 - val_mae: 0.1601\n",
      "Epoch 238/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5872 - mse: 0.0264 - mae: 0.0336 - val_loss: 44.4002 - val_mse: 0.1589 - val_mae: 0.1604\n",
      "Epoch 239/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5827 - mse: 0.0264 - mae: 0.0335 - val_loss: 44.4007 - val_mse: 0.1585 - val_mae: 0.1601\n",
      "Epoch 240/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5785 - mse: 0.0262 - mae: 0.0332 - val_loss: 44.3995 - val_mse: 0.1582 - val_mae: 0.1596\n",
      "Epoch 241/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5771 - mse: 0.0265 - mae: 0.0334 - val_loss: 44.3989 - val_mse: 0.1586 - val_mae: 0.1600\n",
      "Epoch 242/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.5714 - mse: 0.0262 - mae: 0.0330 - val_loss: 44.3980 - val_mse: 0.1589 - val_mae: 0.1603\n",
      "Epoch 243/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5684 - mse: 0.0266 - mae: 0.0333 - val_loss: 44.3983 - val_mse: 0.1584 - val_mae: 0.1598\n",
      "Epoch 244/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5665 - mse: 0.0263 - mae: 0.0329 - val_loss: 44.3970 - val_mse: 0.1589 - val_mae: 0.1602\n",
      "Epoch 245/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5647 - mse: 0.0260 - mae: 0.0326 - val_loss: 44.3971 - val_mse: 0.1584 - val_mae: 0.1598\n",
      "Epoch 246/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5593 - mse: 0.0266 - mae: 0.0330 - val_loss: 44.3961 - val_mse: 0.1582 - val_mae: 0.1596\n",
      "Epoch 247/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5588 - mse: 0.0260 - mae: 0.0324 - val_loss: 44.3957 - val_mse: 0.1586 - val_mae: 0.1599\n",
      "Epoch 248/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5566 - mse: 0.0259 - mae: 0.0322 - val_loss: 44.3951 - val_mse: 0.1591 - val_mae: 0.1604\n",
      "Epoch 249/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5509 - mse: 0.0267 - mae: 0.0328 - val_loss: 44.3945 - val_mse: 0.1585 - val_mae: 0.1598\n",
      "Epoch 250/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5472 - mse: 0.0267 - mae: 0.0327 - val_loss: 44.3941 - val_mse: 0.1584 - val_mae: 0.1597\n",
      "Epoch 251/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5476 - mse: 0.0260 - mae: 0.0320 - val_loss: 44.3941 - val_mse: 0.1583 - val_mae: 0.1595\n",
      "Epoch 252/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5438 - mse: 0.0263 - mae: 0.0322 - val_loss: 44.3934 - val_mse: 0.1585 - val_mae: 0.1597\n",
      "Epoch 253/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.5429 - mse: 0.0259 - mae: 0.0318 - val_loss: 44.3928 - val_mse: 0.1586 - val_mae: 0.1598\n",
      "Epoch 254/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5370 - mse: 0.0270 - mae: 0.0326 - val_loss: 44.3923 - val_mse: 0.1588 - val_mae: 0.1600\n",
      "Epoch 255/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.5369 - mse: 0.0262 - mae: 0.0318 - val_loss: 44.3919 - val_mse: 0.1584 - val_mae: 0.1596\n",
      "Epoch 256/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5329 - mse: 0.0263 - mae: 0.0318 - val_loss: 44.3915 - val_mse: 0.1587 - val_mae: 0.1598\n",
      "Epoch 257/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5329 - mse: 0.0259 - mae: 0.0314 - val_loss: 44.3907 - val_mse: 0.1589 - val_mae: 0.1600\n",
      "Epoch 258/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5274 - mse: 0.0270 - mae: 0.0323 - val_loss: 44.3907 - val_mse: 0.1586 - val_mae: 0.1597\n",
      "Epoch 259/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5265 - mse: 0.0260 - mae: 0.0313 - val_loss: 44.3907 - val_mse: 0.1582 - val_mae: 0.1593\n",
      "Epoch 260/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5252 - mse: 0.0265 - mae: 0.0318 - val_loss: 44.3894 - val_mse: 0.1590 - val_mae: 0.1601\n",
      "Epoch 261/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5203 - mse: 0.0266 - mae: 0.0317 - val_loss: 44.3894 - val_mse: 0.1586 - val_mae: 0.1597\n",
      "Epoch 262/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5199 - mse: 0.0264 - mae: 0.0315 - val_loss: 44.3894 - val_mse: 0.1585 - val_mae: 0.1595\n",
      "Epoch 263/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5194 - mse: 0.0260 - mae: 0.0311 - val_loss: 44.3884 - val_mse: 0.1589 - val_mae: 0.1600\n",
      "Epoch 264/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5152 - mse: 0.0264 - mae: 0.0313 - val_loss: 44.3886 - val_mse: 0.1581 - val_mae: 0.1591\n",
      "Epoch 265/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5134 - mse: 0.0266 - mae: 0.0315 - val_loss: 44.3876 - val_mse: 0.1592 - val_mae: 0.1602\n",
      "Epoch 266/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5105 - mse: 0.0265 - mae: 0.0313 - val_loss: 44.3877 - val_mse: 0.1580 - val_mae: 0.1590\n",
      "Epoch 267/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5119 - mse: 0.0257 - mae: 0.0305 - val_loss: 44.3874 - val_mse: 0.1591 - val_mae: 0.1601\n",
      "Epoch 268/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.5061 - mse: 0.0268 - mae: 0.0314 - val_loss: 44.3869 - val_mse: 0.1582 - val_mae: 0.1592\n",
      "Epoch 269/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5057 - mse: 0.0266 - mae: 0.0312 - val_loss: 44.3865 - val_mse: 0.1591 - val_mae: 0.1600\n",
      "Epoch 270/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5038 - mse: 0.0261 - mae: 0.0307 - val_loss: 44.3861 - val_mse: 0.1582 - val_mae: 0.1591\n",
      "Epoch 271/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.5026 - mse: 0.0265 - mae: 0.0311 - val_loss: 44.3860 - val_mse: 0.1589 - val_mae: 0.1598\n",
      "Epoch 272/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4997 - mse: 0.0262 - mae: 0.0307 - val_loss: 44.3855 - val_mse: 0.1584 - val_mae: 0.1593\n",
      "Epoch 273/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4989 - mse: 0.0260 - mae: 0.0305 - val_loss: 44.3853 - val_mse: 0.1589 - val_mae: 0.1598\n",
      "Epoch 274/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4958 - mse: 0.0268 - mae: 0.0311 - val_loss: 44.3849 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 275/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4940 - mse: 0.0264 - mae: 0.0306 - val_loss: 44.3844 - val_mse: 0.1590 - val_mae: 0.1598\n",
      "Epoch 276/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4921 - mse: 0.0267 - mae: 0.0309 - val_loss: 44.3846 - val_mse: 0.1585 - val_mae: 0.1594\n",
      "Epoch 277/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4927 - mse: 0.0260 - mae: 0.0302 - val_loss: 44.3839 - val_mse: 0.1582 - val_mae: 0.1591\n",
      "Epoch 278/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4897 - mse: 0.0265 - mae: 0.0306 - val_loss: 44.3839 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 279/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4874 - mse: 0.0266 - mae: 0.0306 - val_loss: 44.3832 - val_mse: 0.1592 - val_mae: 0.1601\n",
      "Epoch 280/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4869 - mse: 0.0261 - mae: 0.0302 - val_loss: 44.3831 - val_mse: 0.1585 - val_mae: 0.1593\n",
      "Epoch 281/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4835 - mse: 0.0268 - mae: 0.0307 - val_loss: 44.3830 - val_mse: 0.1588 - val_mae: 0.1596\n",
      "Epoch 282/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4846 - mse: 0.0260 - mae: 0.0300 - val_loss: 44.3826 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 283/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4823 - mse: 0.0261 - mae: 0.0299 - val_loss: 44.3826 - val_mse: 0.1585 - val_mae: 0.1594\n",
      "Epoch 284/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4796 - mse: 0.0268 - mae: 0.0306 - val_loss: 44.3820 - val_mse: 0.1584 - val_mae: 0.1592\n",
      "Epoch 285/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4787 - mse: 0.0263 - mae: 0.0301 - val_loss: 44.3818 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 286/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4775 - mse: 0.0265 - mae: 0.0303 - val_loss: 44.3813 - val_mse: 0.1589 - val_mae: 0.1597\n",
      "Epoch 287/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4758 - mse: 0.0264 - mae: 0.0301 - val_loss: 44.3816 - val_mse: 0.1583 - val_mae: 0.1590\n",
      "Epoch 288/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4738 - mse: 0.0265 - mae: 0.0301 - val_loss: 44.3810 - val_mse: 0.1588 - val_mae: 0.1595\n",
      "Epoch 289/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4730 - mse: 0.0262 - mae: 0.0298 - val_loss: 44.3806 - val_mse: 0.1590 - val_mae: 0.1598\n",
      "Epoch 290/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4710 - mse: 0.0267 - mae: 0.0302 - val_loss: 44.3809 - val_mse: 0.1583 - val_mae: 0.1591\n",
      "Epoch 291/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4718 - mse: 0.0262 - mae: 0.0297 - val_loss: 44.3804 - val_mse: 0.1589 - val_mae: 0.1596\n",
      "Epoch 292/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4684 - mse: 0.0265 - mae: 0.0300 - val_loss: 44.3801 - val_mse: 0.1584 - val_mae: 0.1591\n",
      "Epoch 293/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4677 - mse: 0.0264 - mae: 0.0298 - val_loss: 44.3797 - val_mse: 0.1591 - val_mae: 0.1598\n",
      "Epoch 294/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4665 - mse: 0.0261 - mae: 0.0295 - val_loss: 44.3800 - val_mse: 0.1587 - val_mae: 0.1594\n",
      "Epoch 295/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4644 - mse: 0.0268 - mae: 0.0301 - val_loss: 44.3794 - val_mse: 0.1583 - val_mae: 0.1590\n",
      "Epoch 296/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4651 - mse: 0.0261 - mae: 0.0295 - val_loss: 44.3792 - val_mse: 0.1588 - val_mae: 0.1594\n",
      "Epoch 297/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4623 - mse: 0.0264 - mae: 0.0296 - val_loss: 44.3791 - val_mse: 0.1590 - val_mae: 0.1597\n",
      "Epoch 298/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4620 - mse: 0.0263 - mae: 0.0296 - val_loss: 44.3786 - val_mse: 0.1588 - val_mae: 0.1595\n",
      "Epoch 299/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4601 - mse: 0.0264 - mae: 0.0296 - val_loss: 44.3788 - val_mse: 0.1586 - val_mae: 0.1592\n",
      "Epoch 300/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4592 - mse: 0.0264 - mae: 0.0296 - val_loss: 44.3784 - val_mse: 0.1584 - val_mae: 0.1590\n",
      "Epoch 301/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4586 - mse: 0.0266 - mae: 0.0297 - val_loss: 44.3781 - val_mse: 0.1592 - val_mae: 0.1598\n",
      "Epoch 302/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4563 - mse: 0.0263 - mae: 0.0294 - val_loss: 44.3782 - val_mse: 0.1586 - val_mae: 0.1592\n",
      "Epoch 303/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4562 - mse: 0.0264 - mae: 0.0295 - val_loss: 44.3776 - val_mse: 0.1588 - val_mae: 0.1594\n",
      "Epoch 304/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4544 - mse: 0.0263 - mae: 0.0293 - val_loss: 44.3776 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 305/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4540 - mse: 0.0265 - mae: 0.0295 - val_loss: 44.3776 - val_mse: 0.1584 - val_mae: 0.1590\n",
      "Epoch 306/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4522 - mse: 0.0263 - mae: 0.0293 - val_loss: 44.3772 - val_mse: 0.1586 - val_mae: 0.1592\n",
      "Epoch 307/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4518 - mse: 0.0265 - mae: 0.0294 - val_loss: 44.3769 - val_mse: 0.1592 - val_mae: 0.1598\n",
      "Epoch 308/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4504 - mse: 0.0264 - mae: 0.0293 - val_loss: 44.3771 - val_mse: 0.1582 - val_mae: 0.1588\n",
      "Epoch 309/2100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4495 - mse: 0.0264 - mae: 0.0293 - val_loss: 44.3765 - val_mse: 0.1591 - val_mae: 0.1596\n",
      "Epoch 310/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4485 - mse: 0.0264 - mae: 0.0292 - val_loss: 44.3767 - val_mse: 0.1584 - val_mae: 0.1590\n",
      "Epoch 311/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4472 - mse: 0.0263 - mae: 0.0291 - val_loss: 44.3764 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 312/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4458 - mse: 0.0268 - mae: 0.0295 - val_loss: 44.3762 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 313/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4465 - mse: 0.0261 - mae: 0.0288 - val_loss: 44.3761 - val_mse: 0.1589 - val_mae: 0.1594\n",
      "Epoch 314/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4443 - mse: 0.0267 - mae: 0.0294 - val_loss: 44.3758 - val_mse: 0.1584 - val_mae: 0.1590\n",
      "Epoch 315/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4437 - mse: 0.0264 - mae: 0.0291 - val_loss: 44.3758 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 316/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4430 - mse: 0.0262 - mae: 0.0288 - val_loss: 44.3756 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 317/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4419 - mse: 0.0265 - mae: 0.0291 - val_loss: 44.3754 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 318/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4411 - mse: 0.0265 - mae: 0.0290 - val_loss: 44.3752 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 319/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4399 - mse: 0.0263 - mae: 0.0288 - val_loss: 44.3751 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 320/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4388 - mse: 0.0264 - mae: 0.0289 - val_loss: 44.3748 - val_mse: 0.1590 - val_mae: 0.1595\n",
      "Epoch 321/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4387 - mse: 0.0266 - mae: 0.0291 - val_loss: 44.3750 - val_mse: 0.1584 - val_mae: 0.1589\n",
      "Epoch 322/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4376 - mse: 0.0265 - mae: 0.0289 - val_loss: 44.3745 - val_mse: 0.1590 - val_mae: 0.1595\n",
      "Epoch 323/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.4365 - mse: 0.0264 - mae: 0.0288 - val_loss: 44.3747 - val_mse: 0.1585 - val_mae: 0.1590\n",
      "Epoch 324/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4360 - mse: 0.0265 - mae: 0.0289 - val_loss: 44.3744 - val_mse: 0.1590 - val_mae: 0.1595\n",
      "Epoch 325/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4350 - mse: 0.0264 - mae: 0.0288 - val_loss: 44.3742 - val_mse: 0.1585 - val_mae: 0.1590\n",
      "Epoch 326/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4341 - mse: 0.0264 - mae: 0.0287 - val_loss: 44.3740 - val_mse: 0.1585 - val_mae: 0.1589\n",
      "Epoch 327/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4334 - mse: 0.0264 - mae: 0.0288 - val_loss: 44.3740 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 328/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4327 - mse: 0.0264 - mae: 0.0287 - val_loss: 44.3736 - val_mse: 0.1591 - val_mae: 0.1596\n",
      "Epoch 329/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4322 - mse: 0.0260 - mae: 0.0283 - val_loss: 44.3738 - val_mse: 0.1584 - val_mae: 0.1589\n",
      "Epoch 330/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4308 - mse: 0.0268 - mae: 0.0290 - val_loss: 44.3735 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 331/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4302 - mse: 0.0264 - mae: 0.0287 - val_loss: 44.3734 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 332/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4299 - mse: 0.0265 - mae: 0.0287 - val_loss: 44.3733 - val_mse: 0.1584 - val_mae: 0.1588\n",
      "Epoch 333/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4289 - mse: 0.0264 - mae: 0.0286 - val_loss: 44.3732 - val_mse: 0.1585 - val_mae: 0.1589\n",
      "Epoch 334/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4282 - mse: 0.0264 - mae: 0.0286 - val_loss: 44.3730 - val_mse: 0.1590 - val_mae: 0.1594\n",
      "Epoch 335/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4272 - mse: 0.0264 - mae: 0.0285 - val_loss: 44.3729 - val_mse: 0.1585 - val_mae: 0.1589\n",
      "Epoch 336/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4268 - mse: 0.0264 - mae: 0.0286 - val_loss: 44.3728 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 337/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4266 - mse: 0.0265 - mae: 0.0286 - val_loss: 44.3726 - val_mse: 0.1586 - val_mae: 0.1591\n",
      "Epoch 338/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4251 - mse: 0.0266 - mae: 0.0286 - val_loss: 44.3725 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 339/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4247 - mse: 0.0261 - mae: 0.0281 - val_loss: 44.3723 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 340/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4245 - mse: 0.0266 - mae: 0.0287 - val_loss: 44.3724 - val_mse: 0.1583 - val_mae: 0.1587\n",
      "Epoch 341/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4238 - mse: 0.0260 - mae: 0.0280 - val_loss: 44.3722 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 342/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4225 - mse: 0.0268 - mae: 0.0288 - val_loss: 44.3721 - val_mse: 0.1582 - val_mae: 0.1586\n",
      "Epoch 343/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4222 - mse: 0.0265 - mae: 0.0284 - val_loss: 44.3720 - val_mse: 0.1587 - val_mae: 0.1591\n",
      "Epoch 344/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4216 - mse: 0.0265 - mae: 0.0284 - val_loss: 44.3719 - val_mse: 0.1587 - val_mae: 0.1591\n",
      "Epoch 345/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4210 - mse: 0.0265 - mae: 0.0285 - val_loss: 44.3717 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 346/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4206 - mse: 0.0260 - mae: 0.0279 - val_loss: 44.3717 - val_mse: 0.1582 - val_mae: 0.1586\n",
      "Epoch 347/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4188 - mse: 0.0272 - mae: 0.0290 - val_loss: 44.3714 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 348/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4198 - mse: 0.0261 - mae: 0.0280 - val_loss: 44.3716 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 349/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4183 - mse: 0.0267 - mae: 0.0286 - val_loss: 44.3714 - val_mse: 0.1581 - val_mae: 0.1585\n",
      "Epoch 350/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4182 - mse: 0.0263 - mae: 0.0281 - val_loss: 44.3713 - val_mse: 0.1592 - val_mae: 0.1596\n",
      "Epoch 351/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4174 - mse: 0.0265 - mae: 0.0283 - val_loss: 44.3710 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 352/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4166 - mse: 0.0266 - mae: 0.0284 - val_loss: 44.3712 - val_mse: 0.1586 - val_mae: 0.1590\n",
      "Epoch 353/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4165 - mse: 0.0263 - mae: 0.0281 - val_loss: 44.3709 - val_mse: 0.1585 - val_mae: 0.1588\n",
      "Epoch 354/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4155 - mse: 0.0264 - mae: 0.0282 - val_loss: 44.3709 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 355/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4154 - mse: 0.0264 - mae: 0.0281 - val_loss: 44.3707 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 356/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4148 - mse: 0.0266 - mae: 0.0283 - val_loss: 44.3706 - val_mse: 0.1586 - val_mae: 0.1590\n",
      "Epoch 357/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4141 - mse: 0.0265 - mae: 0.0282 - val_loss: 44.3707 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 358/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4132 - mse: 0.0262 - mae: 0.0279 - val_loss: 44.3705 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 359/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4134 - mse: 0.0266 - mae: 0.0283 - val_loss: 44.3703 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 360/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4126 - mse: 0.0265 - mae: 0.0281 - val_loss: 44.3703 - val_mse: 0.1581 - val_mae: 0.1585\n",
      "Epoch 361/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4120 - mse: 0.0264 - mae: 0.0280 - val_loss: 44.3701 - val_mse: 0.1592 - val_mae: 0.1595\n",
      "Epoch 362/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4116 - mse: 0.0266 - mae: 0.0282 - val_loss: 44.3703 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 363/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4111 - mse: 0.0265 - mae: 0.0281 - val_loss: 44.3700 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 364/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4105 - mse: 0.0264 - mae: 0.0280 - val_loss: 44.3700 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 365/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4100 - mse: 0.0264 - mae: 0.0279 - val_loss: 44.3699 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 366/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4097 - mse: 0.0266 - mae: 0.0281 - val_loss: 44.3697 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 367/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4090 - mse: 0.0264 - mae: 0.0279 - val_loss: 44.3698 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 368/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4086 - mse: 0.0264 - mae: 0.0279 - val_loss: 44.3696 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 369/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4082 - mse: 0.0265 - mae: 0.0280 - val_loss: 44.3696 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 370/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4081 - mse: 0.0267 - mae: 0.0282 - val_loss: 44.3694 - val_mse: 0.1585 - val_mae: 0.1588\n",
      "Epoch 371/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4072 - mse: 0.0264 - mae: 0.0279 - val_loss: 44.3694 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 372/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4071 - mse: 0.0260 - mae: 0.0275 - val_loss: 44.3693 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 373/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4060 - mse: 0.0267 - mae: 0.0282 - val_loss: 44.3692 - val_mse: 0.1592 - val_mae: 0.1595\n",
      "Epoch 374/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4060 - mse: 0.0265 - mae: 0.0279 - val_loss: 44.3693 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 375/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4059 - mse: 0.0267 - mae: 0.0281 - val_loss: 44.3691 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 376/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4050 - mse: 0.0263 - mae: 0.0277 - val_loss: 44.3689 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 377/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4046 - mse: 0.0267 - mae: 0.0281 - val_loss: 44.3690 - val_mse: 0.1584 - val_mae: 0.1587\n",
      "Epoch 378/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4043 - mse: 0.0263 - mae: 0.0277 - val_loss: 44.3689 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 379/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4041 - mse: 0.0264 - mae: 0.0278 - val_loss: 44.3688 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 380/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.4035 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3687 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 381/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4029 - mse: 0.0264 - mae: 0.0277 - val_loss: 44.3687 - val_mse: 0.1593 - val_mae: 0.1596\n",
      "Epoch 382/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4030 - mse: 0.0266 - mae: 0.0280 - val_loss: 44.3685 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 383/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4022 - mse: 0.0266 - mae: 0.0280 - val_loss: 44.3686 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 384/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4020 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3685 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 385/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4016 - mse: 0.0263 - mae: 0.0276 - val_loss: 44.3683 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 386/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4014 - mse: 0.0264 - mae: 0.0277 - val_loss: 44.3684 - val_mse: 0.1584 - val_mae: 0.1587\n",
      "Epoch 387/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.4009 - mse: 0.0266 - mae: 0.0279 - val_loss: 44.3683 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 388/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.4004 - mse: 0.0263 - mae: 0.0276 - val_loss: 44.3682 - val_mse: 0.1592 - val_mae: 0.1595\n",
      "Epoch 389/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3999 - mse: 0.0264 - mae: 0.0276 - val_loss: 44.3681 - val_mse: 0.1583 - val_mae: 0.1586\n",
      "Epoch 390/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3995 - mse: 0.0269 - mae: 0.0281 - val_loss: 44.3681 - val_mse: 0.1594 - val_mae: 0.1597\n",
      "Epoch 391/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3999 - mse: 0.0263 - mae: 0.0275 - val_loss: 44.3680 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 392/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3987 - mse: 0.0263 - mae: 0.0275 - val_loss: 44.3681 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 393/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3988 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3679 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 394/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3984 - mse: 0.0265 - mae: 0.0277 - val_loss: 44.3678 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 395/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3978 - mse: 0.0264 - mae: 0.0276 - val_loss: 44.3678 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 396/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3979 - mse: 0.0266 - mae: 0.0278 - val_loss: 44.3678 - val_mse: 0.1582 - val_mae: 0.1584\n",
      "Epoch 397/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3973 - mse: 0.0265 - mae: 0.0276 - val_loss: 44.3677 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 398/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3971 - mse: 0.0265 - mae: 0.0277 - val_loss: 44.3676 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 399/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3965 - mse: 0.0263 - mae: 0.0275 - val_loss: 44.3675 - val_mse: 0.1592 - val_mae: 0.1595\n",
      "Epoch 400/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3963 - mse: 0.0264 - mae: 0.0275 - val_loss: 44.3675 - val_mse: 0.1581 - val_mae: 0.1584\n",
      "Epoch 401/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3963 - mse: 0.0266 - mae: 0.0278 - val_loss: 44.3675 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 402/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3955 - mse: 0.0263 - mae: 0.0274 - val_loss: 44.3674 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 403/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3956 - mse: 0.0266 - mae: 0.0278 - val_loss: 44.3674 - val_mse: 0.1582 - val_mae: 0.1584\n",
      "Epoch 404/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3953 - mse: 0.0260 - mae: 0.0271 - val_loss: 44.3673 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 405/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3947 - mse: 0.0270 - mae: 0.0280 - val_loss: 44.3673 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 406/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3943 - mse: 0.0263 - mae: 0.0274 - val_loss: 44.3672 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 407/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3943 - mse: 0.0266 - mae: 0.0276 - val_loss: 44.3671 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 408/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3940 - mse: 0.0265 - mae: 0.0276 - val_loss: 44.3672 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 409/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3934 - mse: 0.0264 - mae: 0.0274 - val_loss: 44.3669 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 410/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3933 - mse: 0.0263 - mae: 0.0274 - val_loss: 44.3670 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 411/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3933 - mse: 0.0267 - mae: 0.0277 - val_loss: 44.3670 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 412/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3928 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3669 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 413/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3926 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3668 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 414/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3920 - mse: 0.0266 - mae: 0.0276 - val_loss: 44.3668 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 415/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3920 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3667 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 416/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3916 - mse: 0.0261 - mae: 0.0271 - val_loss: 44.3667 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 417/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3915 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3666 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 418/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3911 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3666 - val_mse: 0.1594 - val_mae: 0.1596\n",
      "Epoch 419/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3912 - mse: 0.0261 - mae: 0.0270 - val_loss: 44.3666 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 420/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3906 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3665 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 421/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3902 - mse: 0.0268 - mae: 0.0278 - val_loss: 44.3665 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 422/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3901 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3664 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 423/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3900 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3664 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 424/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3896 - mse: 0.0264 - mae: 0.0273 - val_loss: 44.3663 - val_mse: 0.1581 - val_mae: 0.1583\n",
      "Epoch 425/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3893 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3662 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 426/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3892 - mse: 0.0267 - mae: 0.0276 - val_loss: 44.3663 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 427/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3890 - mse: 0.0263 - mae: 0.0272 - val_loss: 44.3662 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 428/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3886 - mse: 0.0267 - mae: 0.0275 - val_loss: 44.3662 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 429/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3882 - mse: 0.0266 - mae: 0.0274 - val_loss: 44.3661 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 430/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3884 - mse: 0.0262 - mae: 0.0271 - val_loss: 44.3661 - val_mse: 0.1594 - val_mae: 0.1596\n",
      "Epoch 431/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3881 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3660 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 432/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3876 - mse: 0.0265 - mae: 0.0273 - val_loss: 44.3660 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 433/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3875 - mse: 0.0263 - mae: 0.0272 - val_loss: 44.3660 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 434/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3875 - mse: 0.0267 - mae: 0.0275 - val_loss: 44.3659 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 435/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3872 - mse: 0.0260 - mae: 0.0269 - val_loss: 44.3659 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 436/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3864 - mse: 0.0272 - mae: 0.0280 - val_loss: 44.3659 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 437/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3868 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3658 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 438/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3866 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3658 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 439/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3862 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3657 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 440/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3859 - mse: 0.0267 - mae: 0.0274 - val_loss: 44.3657 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 441/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3859 - mse: 0.0263 - mae: 0.0271 - val_loss: 44.3657 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 442/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3854 - mse: 0.0263 - mae: 0.0271 - val_loss: 44.3656 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 443/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3854 - mse: 0.0266 - mae: 0.0274 - val_loss: 44.3656 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 444/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3853 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3656 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 445/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3849 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3655 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 446/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3848 - mse: 0.0262 - mae: 0.0270 - val_loss: 44.3655 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 447/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3846 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3654 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 448/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3843 - mse: 0.0261 - mae: 0.0269 - val_loss: 44.3654 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 449/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3844 - mse: 0.0267 - mae: 0.0274 - val_loss: 44.3654 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 450/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3839 - mse: 0.0265 - mae: 0.0272 - val_loss: 44.3654 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 451/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3839 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3653 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 452/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3835 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3653 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 453/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3836 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3653 - val_mse: 0.1594 - val_mae: 0.1596\n",
      "Epoch 454/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3832 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3652 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 455/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3832 - mse: 0.0263 - mae: 0.0270 - val_loss: 44.3651 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 456/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3829 - mse: 0.0265 - mae: 0.0272 - val_loss: 44.3652 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 457/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3826 - mse: 0.0263 - mae: 0.0270 - val_loss: 44.3652 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 458/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3825 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3651 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 459/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3825 - mse: 0.0267 - mae: 0.0273 - val_loss: 44.3651 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 460/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3821 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3651 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 461/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3820 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3650 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 462/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3819 - mse: 0.0265 - mae: 0.0272 - val_loss: 44.3649 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 463/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3819 - mse: 0.0262 - mae: 0.0269 - val_loss: 44.3650 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 464/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3812 - mse: 0.0272 - mae: 0.0278 - val_loss: 44.3650 - val_mse: 0.1582 - val_mae: 0.1584\n",
      "Epoch 465/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3816 - mse: 0.0261 - mae: 0.0268 - val_loss: 44.3648 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 466/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3812 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3649 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 467/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3810 - mse: 0.0264 - mae: 0.0271 - val_loss: 44.3649 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 468/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3811 - mse: 0.0262 - mae: 0.0269 - val_loss: 44.3648 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 469/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3806 - mse: 0.0271 - mae: 0.0277 - val_loss: 44.3648 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 470/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3807 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3648 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 471/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3803 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3647 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 472/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3804 - mse: 0.0266 - mae: 0.0272 - val_loss: 44.3647 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 473/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3801 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3647 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 474/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3799 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3647 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 475/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3799 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3646 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 476/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3795 - mse: 0.0268 - mae: 0.0273 - val_loss: 44.3646 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 477/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3796 - mse: 0.0267 - mae: 0.0273 - val_loss: 44.3646 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 478/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3793 - mse: 0.0263 - mae: 0.0269 - val_loss: 44.3645 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 479/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3794 - mse: 0.0267 - mae: 0.0273 - val_loss: 44.3646 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 480/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3791 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3645 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 481/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3789 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3645 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 482/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3788 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3644 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 483/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3788 - mse: 0.0266 - mae: 0.0271 - val_loss: 44.3645 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 484/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3783 - mse: 0.0269 - mae: 0.0274 - val_loss: 44.3644 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 485/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3785 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3644 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 486/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3783 - mse: 0.0262 - mae: 0.0268 - val_loss: 44.3643 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 487/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3781 - mse: 0.0268 - mae: 0.0273 - val_loss: 44.3644 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 488/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3780 - mse: 0.0263 - mae: 0.0268 - val_loss: 44.3643 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 489/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3779 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3643 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 490/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3777 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3643 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 491/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3775 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3642 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 492/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3776 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3642 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 493/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3774 - mse: 0.0261 - mae: 0.0266 - val_loss: 44.3642 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 494/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3772 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3641 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 495/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3770 - mse: 0.0268 - mae: 0.0273 - val_loss: 44.3642 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 496/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3769 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3641 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 497/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3770 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3641 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 498/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3765 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3641 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 499/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3768 - mse: 0.0263 - mae: 0.0268 - val_loss: 44.3641 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 500/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3764 - mse: 0.0266 - mae: 0.0271 - val_loss: 44.3641 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 501/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3765 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3640 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 502/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3763 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3640 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 503/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3761 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3640 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 504/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3758 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3640 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 505/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3760 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3640 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 506/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3758 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3639 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 507/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3757 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3640 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 508/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3755 - mse: 0.0269 - mae: 0.0274 - val_loss: 44.3639 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 509/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3757 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3639 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 510/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3754 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3639 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 511/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3752 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3638 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 512/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3751 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3638 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 513/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3750 - mse: 0.0268 - mae: 0.0272 - val_loss: 44.3638 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 514/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3751 - mse: 0.0259 - mae: 0.0263 - val_loss: 44.3638 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 515/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3746 - mse: 0.0272 - mae: 0.0276 - val_loss: 44.3638 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 516/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3748 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3638 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 517/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3747 - mse: 0.0267 - mae: 0.0271 - val_loss: 44.3637 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 518/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3745 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3637 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 519/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3743 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3637 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 520/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3745 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3637 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 521/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3742 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3637 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 522/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3741 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3637 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 523/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3740 - mse: 0.0268 - mae: 0.0272 - val_loss: 44.3636 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 524/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3739 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3636 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 525/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3740 - mse: 0.0267 - mae: 0.0271 - val_loss: 44.3636 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 526/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3738 - mse: 0.0260 - mae: 0.0264 - val_loss: 44.3636 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 527/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3736 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3636 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 528/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3736 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3635 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 529/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3734 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3635 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 530/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3733 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3635 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 531/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3734 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3635 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 532/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3731 - mse: 0.0271 - mae: 0.0275 - val_loss: 44.3635 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 533/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3732 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3634 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 534/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3730 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3635 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 535/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3730 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3634 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 536/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3728 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 537/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3727 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 538/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3728 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3634 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 539/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3725 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3634 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 540/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3726 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 541/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3724 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3633 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 542/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3724 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3633 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 543/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3722 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3633 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 544/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3722 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3633 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 545/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3721 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3633 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 546/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3719 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3633 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 547/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3720 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3633 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 548/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3718 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3632 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 549/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3719 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3632 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 550/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3718 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3632 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 551/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3715 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3632 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 552/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3716 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3632 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 553/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3715 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3632 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 554/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3715 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3632 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 555/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3712 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3631 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 556/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3714 - mse: 0.0263 - mae: 0.0266 - val_loss: 44.3632 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 557/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3712 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3631 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 558/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3711 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3631 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 559/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3710 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3631 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 560/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3710 - mse: 0.0268 - mae: 0.0272 - val_loss: 44.3631 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 561/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3709 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3631 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 562/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3709 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3631 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 563/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3708 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3631 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 564/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3707 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3631 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 565/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3706 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3630 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 566/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3705 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3630 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 567/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3705 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3630 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 568/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3705 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3630 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 569/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3702 - mse: 0.0272 - mae: 0.0275 - val_loss: 44.3630 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 570/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3704 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3630 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 571/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3702 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3630 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 572/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3702 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3629 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 573/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3701 - mse: 0.0263 - mae: 0.0266 - val_loss: 44.3630 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 574/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3700 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3629 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 575/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3700 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3629 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 576/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3699 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3629 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 577/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3697 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3629 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 578/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3699 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3629 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 579/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3697 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3629 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 580/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3697 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3629 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 581/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3696 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3629 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 582/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3696 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3629 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 583/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3695 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3628 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 584/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3695 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3629 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 585/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3693 - mse: 0.0271 - mae: 0.0274 - val_loss: 44.3628 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 586/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3693 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3628 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 587/2100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 44.3693 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3628 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 588/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3692 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3628 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 589/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3693 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3628 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 590/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3691 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3628 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 591/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3690 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3628 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 592/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3690 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 593/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3689 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 594/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3688 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3628 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 595/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3688 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3627 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 596/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3689 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3627 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 597/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3687 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3627 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 598/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3687 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3627 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 599/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3686 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 600/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3686 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3627 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 601/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3685 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3627 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 602/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3684 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3627 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 603/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3685 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3627 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 604/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3684 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3626 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 605/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3684 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3626 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 606/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3682 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3627 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 607/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3682 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3626 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 608/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3682 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3626 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 609/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3681 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3626 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 610/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3681 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3626 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 611/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3681 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3626 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 612/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3680 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3626 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 613/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3679 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3626 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 614/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3680 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3626 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 615/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3678 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3626 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 616/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3679 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3626 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 617/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3678 - mse: 0.0270 - mae: 0.0272 - val_loss: 44.3625 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 618/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3677 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3625 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 619/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3677 - mse: 0.0259 - mae: 0.0261 - val_loss: 44.3625 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 620/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3676 - mse: 0.0270 - mae: 0.0272 - val_loss: 44.3625 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 621/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3676 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3625 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 622/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3675 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3625 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 623/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3676 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3625 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 624/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3675 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3625 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 625/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3674 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3625 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 626/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3675 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3625 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 627/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3672 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3625 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 628/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3674 - mse: 0.0258 - mae: 0.0260 - val_loss: 44.3624 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 629/2100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3673 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3625 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 630/2100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 44.3672 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3624 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 631/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3672 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 632/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3672 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3624 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 633/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3671 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 634/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3671 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3624 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 635/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3670 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3624 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 636/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3671 - mse: 0.0258 - mae: 0.0260 - val_loss: 44.3624 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 637/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3669 - mse: 0.0270 - mae: 0.0272 - val_loss: 44.3624 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 638/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3669 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 639/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3669 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 640/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3668 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 641/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3668 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 642/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3667 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3624 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 643/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3668 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3624 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 644/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3667 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3624 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 645/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3666 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3623 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 646/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3666 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3623 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 647/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3666 - mse: 0.0260 - mae: 0.0262 - val_loss: 44.3623 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 648/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3665 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3623 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 649/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3665 - mse: 0.0271 - mae: 0.0273 - val_loss: 44.3623 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 650/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3665 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3623 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 651/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3664 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3623 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 652/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3664 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3623 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 653/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3664 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3623 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 654/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3664 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3623 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 655/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3663 - mse: 0.0270 - mae: 0.0272 - val_loss: 44.3623 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 656/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3662 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3623 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 657/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3662 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3623 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 658/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3662 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3623 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 659/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3661 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3623 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 660/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3662 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3623 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 661/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3661 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 662/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3660 - mse: 0.0271 - mae: 0.0273 - val_loss: 44.3622 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 663/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3660 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3622 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 664/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3660 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 665/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3660 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3622 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 666/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3660 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3622 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 667/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3659 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3622 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 668/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3659 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 669/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3658 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 670/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3659 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3622 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 671/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3658 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 672/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3658 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 673/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3657 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3622 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 674/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3658 - mse: 0.0258 - mae: 0.0259 - val_loss: 44.3622 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 675/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3657 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3622 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 676/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3656 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 677/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3656 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3622 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 678/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3656 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 679/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3656 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 680/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3655 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 681/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3655 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3621 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 682/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3654 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 683/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3655 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3621 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 684/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3654 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 685/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3654 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 686/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3654 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3621 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 687/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3653 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 688/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3653 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 689/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3653 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 690/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3653 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3621 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 691/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3652 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3621 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 692/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3652 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 693/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3652 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3621 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 694/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3651 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 695/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3652 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 696/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3651 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 697/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3651 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 698/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3651 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3621 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 699/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3651 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 700/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3650 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 701/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3649 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 702/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3650 - mse: 0.0258 - mae: 0.0259 - val_loss: 44.3621 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 703/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3649 - mse: 0.0271 - mae: 0.0272 - val_loss: 44.3621 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 704/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3649 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3620 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 705/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3649 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 706/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3649 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 707/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3649 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 708/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3648 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 709/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3648 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3620 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 710/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3648 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3620 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 711/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3648 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 712/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3648 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 713/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3647 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 714/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3647 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3620 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 715/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3647 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 716/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3647 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 717/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3646 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 718/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3646 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 719/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3646 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 720/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3646 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 721/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3645 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 722/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3645 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 723/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3645 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 724/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3645 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 725/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3645 - mse: 0.0258 - mae: 0.0259 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 726/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3644 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 727/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3644 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3620 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 728/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3644 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 729/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3644 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 730/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3644 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 731/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3644 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 732/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3643 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 733/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3643 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 734/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3643 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 735/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3643 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 736/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3643 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 737/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3642 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3619 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 738/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3642 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3619 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 739/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3642 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 740/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3642 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 741/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3642 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 742/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3641 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3619 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 743/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3641 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 744/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3641 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 745/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3641 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 746/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3641 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 747/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3641 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 748/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3640 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 749/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3640 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 750/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3640 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 751/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3640 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 752/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3640 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 753/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3639 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3619 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 754/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3639 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 755/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3639 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 756/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3639 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 757/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3639 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 758/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3639 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 759/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3639 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 760/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3638 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 761/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3638 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 762/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3638 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 763/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3638 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 764/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3638 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 765/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3638 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 766/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3637 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 767/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3637 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 768/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3637 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 769/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3637 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 770/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3637 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3618 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 771/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3637 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 772/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 773/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3636 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 774/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 775/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 776/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 777/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 778/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3636 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 779/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 780/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 781/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 782/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 783/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 784/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 785/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3635 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 786/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3635 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 787/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3634 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 788/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3634 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 789/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3634 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 790/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3634 - mse: 0.0259 - mae: 0.0260 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 791/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3634 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 792/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3634 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 793/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3634 - mse: 0.0258 - mae: 0.0259 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 794/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3633 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 795/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3634 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 796/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3633 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 797/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3633 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 798/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3633 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 799/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3633 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 800/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3633 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 801/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3633 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 802/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3633 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 803/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3633 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 804/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 805/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3632 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 806/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3632 - mse: 0.0271 - mae: 0.0272 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 807/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 808/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 809/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3632 - mse: 0.0258 - mae: 0.0259 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 810/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 811/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 812/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3632 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 813/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 814/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 815/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 816/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 817/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3631 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 818/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3631 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 819/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3631 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 820/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 821/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 822/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3631 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 823/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 824/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 825/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3630 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 826/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 827/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3630 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 828/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 829/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 830/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 831/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3630 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 832/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 833/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3629 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 834/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3629 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 835/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3629 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 836/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3629 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 837/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3629 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 838/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 839/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3629 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 840/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3629 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 841/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 842/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3629 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 843/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 844/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 845/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 846/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3628 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 847/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 848/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 849/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3628 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 850/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 851/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3628 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 852/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 853/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 854/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 855/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 856/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3627 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 857/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 858/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 859/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 860/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 861/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 862/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 863/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 864/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 865/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 866/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 867/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 868/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 869/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 870/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 871/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 872/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 873/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 874/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 875/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3626 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 876/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3626 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 877/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 878/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 879/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3626 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 880/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 881/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3625 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 882/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 883/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 884/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 885/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3625 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 886/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 887/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 888/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 889/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 890/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 891/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 892/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 893/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 894/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 895/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 896/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3625 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 897/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 898/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3624 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 899/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 900/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3624 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 901/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3624 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 902/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3624 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 903/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 904/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3624 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 905/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 906/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 907/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 908/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 909/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3624 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 910/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3624 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 911/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 912/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 913/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3623 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 914/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 915/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 916/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 917/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 918/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 919/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 920/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 921/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 922/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 923/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 924/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 925/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 926/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 927/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 928/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3623 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 929/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 930/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 931/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 932/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 933/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 934/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 935/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 936/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 937/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 938/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 939/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 940/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 941/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 942/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 943/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 944/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 945/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 946/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 947/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 948/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3622 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 949/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 950/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 951/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3621 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 952/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3621 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 953/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 954/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 955/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 956/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 957/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 958/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 959/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 960/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 961/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 962/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 963/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 964/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 965/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3616 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 966/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 967/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 968/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3621 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 969/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3621 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 970/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 971/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3621 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 972/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 973/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 974/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3621 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 975/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3621 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 976/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3620 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 977/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 978/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 979/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 980/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 981/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 982/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 983/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 984/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 985/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 986/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 987/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 988/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3620 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 989/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 990/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 991/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 992/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 993/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 994/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 995/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3620 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 996/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 997/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 998/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 999/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3620 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1000/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1001/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1002/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1003/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3620 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1004/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1005/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1006/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1007/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1008/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3619 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1009/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1010/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1011/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1012/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1013/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1014/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1015/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1016/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1017/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1018/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1019/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1020/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1021/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1022/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1023/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3619 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1024/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1025/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1026/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1027/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1028/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1029/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 1030/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1031/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1032/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1033/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1034/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1035/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1036/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3619 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1037/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1038/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3619 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1039/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1040/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1041/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1042/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1043/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1044/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1045/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1046/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1047/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1048/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1049/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1050/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1051/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1052/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1053/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1054/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1055/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1056/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1057/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1058/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1059/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1060/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1061/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1062/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1063/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1064/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1065/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1066/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1067/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1068/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1069/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1070/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1071/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1072/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1073/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1074/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1075/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1076/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1077/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1078/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1079/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1080/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1081/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3618 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1082/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3617 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1083/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3618 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1084/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1085/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1086/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1087/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1088/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1089/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1090/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1091/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1092/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1093/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1094/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1095/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1096/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1097/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1098/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1099/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1100/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1101/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1102/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1103/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1104/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1105/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1106/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1107/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1108/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1109/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1110/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1111/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1112/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1113/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1114/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1115/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1116/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1117/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1118/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1119/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1120/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1121/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1122/2100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 44.3617 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1123/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1124/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1125/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1126/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1127/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1128/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1129/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1130/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1131/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1132/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1133/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1134/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1135/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1136/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3617 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1137/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1138/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1139/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1140/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1141/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1142/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3617 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1143/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3617 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1144/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3617 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1145/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1146/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1147/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1148/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1149/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1150/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1151/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1152/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1153/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1154/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1155/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1156/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1157/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1158/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1159/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1160/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1161/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1162/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1163/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1164/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1165/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1166/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1167/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1168/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1169/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1170/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1171/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1172/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1173/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1174/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1175/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1176/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1177/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1178/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1179/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1180/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1181/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1182/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1183/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1184/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1185/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1186/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1187/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1188/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1189/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1190/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1191/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1192/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1193/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1194/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1195/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1196/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1197/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1198/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1199/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1200/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1201/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1202/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1203/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1204/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1205/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1206/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1207/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1208/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1209/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1210/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1211/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1212/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1213/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1214/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1215/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1216/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1217/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1218/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1219/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1220/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1221/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1222/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1223/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1224/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1225/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1226/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1227/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1228/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1229/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1230/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1231/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1232/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1233/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1234/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1235/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1236/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1237/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1238/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1239/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1240/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1241/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1242/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3616 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1243/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1244/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1245/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1246/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1247/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3616 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1248/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1249/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3616 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1250/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1251/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1252/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1253/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1254/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1255/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1256/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1257/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1258/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1259/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1260/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1261/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1262/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1263/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1264/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1265/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1266/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1267/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1268/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1269/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1270/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1271/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1272/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1273/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1274/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1275/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1276/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1277/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1278/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1279/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1280/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1281/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1282/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1283/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1284/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1285/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1286/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1287/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1288/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1289/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1290/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1291/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1292/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1293/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1294/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1295/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1296/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1297/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1298/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1299/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1300/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1301/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1302/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1303/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1304/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1305/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1306/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1307/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1308/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1309/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1310/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1311/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1312/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1313/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1314/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1315/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1316/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1317/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1318/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1319/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1320/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1321/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1322/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1323/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1324/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1325/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1326/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1327/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1328/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1329/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1330/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1331/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1332/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1333/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1334/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1335/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1336/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1337/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1338/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1339/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1340/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1341/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1342/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1343/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1344/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1345/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1346/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1347/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1348/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1349/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1350/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1351/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1352/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1353/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1354/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1355/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1356/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1357/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1358/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1359/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1360/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1361/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1362/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1363/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1364/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1365/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1366/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1367/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1368/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1369/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1370/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1371/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1372/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1373/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1374/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1375/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1376/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1377/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1378/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1379/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1380/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1381/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1382/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1383/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1384/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1385/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1386/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1387/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1388/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1389/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1390/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1391/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1392/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1393/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1394/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1395/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1396/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1397/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1398/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1399/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1400/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1401/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1402/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1403/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1404/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1405/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1406/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1407/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1408/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1409/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1410/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1411/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1412/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1413/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1414/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1415/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1416/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1417/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1418/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1419/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1420/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1421/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1422/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1423/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1424/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1425/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1426/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1427/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1428/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1429/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1430/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1431/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1432/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1433/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1434/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1435/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1436/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1437/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1438/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1439/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1440/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1441/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1442/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1443/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1444/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1445/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1446/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1447/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1448/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1449/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1450/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1451/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1452/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1453/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1454/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1455/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1456/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1457/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1458/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1459/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1460/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1461/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1462/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1463/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1464/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1465/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1466/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1467/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1468/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1469/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1470/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1471/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1472/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1473/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1474/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1475/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1476/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1477/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1478/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1479/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1480/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1481/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1482/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1483/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1484/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1485/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1486/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1487/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1488/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1489/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1490/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1491/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1492/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1493/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1494/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1495/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1496/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1497/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1498/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1499/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1500/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1501/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1502/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1503/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1504/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1505/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1506/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1507/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1508/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1509/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1510/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1511/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1512/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1513/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1514/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1515/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1516/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1517/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1518/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1519/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1520/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1521/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1522/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1523/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1524/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1525/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1526/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1527/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1528/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1529/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1530/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1531/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1532/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1533/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1534/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1535/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1536/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1537/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1538/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1539/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1540/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1541/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1542/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1543/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1544/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1545/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1546/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1547/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1548/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1549/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1550/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1551/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1552/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1553/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1554/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1555/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1556/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1557/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1558/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1559/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1560/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1561/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1562/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1563/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1564/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1565/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1566/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1567/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1568/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1569/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1570/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1571/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1572/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1573/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1574/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1575/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1576/2100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 44.3615 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1577/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1578/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1579/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1580/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1581/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1582/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1583/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1584/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1585/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1586/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1587/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1588/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1589/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1590/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1591/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1592/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1593/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1594/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1595/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1596/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1597/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1598/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1599/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1600/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1601/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1602/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1603/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1604/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1605/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1606/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1607/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1608/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1609/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1610/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1611/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1612/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1613/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1614/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1615/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1616/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1617/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1618/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1619/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1620/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1621/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1622/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1623/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1624/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1625/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1626/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1627/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1628/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1629/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1630/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1631/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1632/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1633/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1634/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1635/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1636/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1637/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1638/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1639/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1640/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1641/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1642/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1643/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1644/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1645/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1646/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1647/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1648/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1649/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1650/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1651/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1652/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3615 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1653/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3615 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1654/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1655/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1656/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1657/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3615 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1658/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3615 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1659/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1660/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1661/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1662/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1663/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3615 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1664/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1665/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1666/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1667/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1668/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1669/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1670/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1671/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1672/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1673/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1674/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1675/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1676/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1677/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1678/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1679/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1680/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1681/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1682/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1683/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1684/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1685/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1686/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1687/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1688/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1689/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1690/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1691/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1692/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1693/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1694/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1695/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1696/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1697/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1698/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1699/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1700/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1701/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1702/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1703/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1704/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1705/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1706/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1707/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1708/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1709/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1710/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1711/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1712/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1713/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1714/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1715/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1716/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1717/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1718/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1719/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1720/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1721/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1722/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1723/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1724/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1725/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1726/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1727/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1728/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1729/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1730/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1731/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1732/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1733/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1734/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1735/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1736/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1737/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1738/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1739/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1740/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1741/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1742/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1743/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1744/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1745/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1746/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1747/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1748/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1749/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1750/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1751/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1752/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1753/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1754/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1755/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1756/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1757/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1758/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1759/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1760/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1761/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1762/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1763/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1764/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1765/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1766/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1767/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1768/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1769/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1770/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1771/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1772/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1773/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1774/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1775/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1776/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1777/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1778/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1779/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1780/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1781/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1782/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1783/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1784/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1785/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1786/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1787/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1788/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1789/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1790/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1791/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1792/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1793/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1794/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1795/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1796/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1797/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1798/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1799/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1800/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1801/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1802/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1803/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1804/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1805/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1806/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1807/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1808/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1809/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1810/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1811/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1812/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1813/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3615 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1814/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1815/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1816/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1817/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1818/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1819/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1820/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1821/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1822/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1823/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1824/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1825/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3615 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1826/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3615 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1827/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1828/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1829/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1830/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1831/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1832/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1833/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1834/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1835/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1836/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1837/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1838/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1839/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1840/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1841/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1842/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1843/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1844/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1845/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1846/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1847/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1848/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1849/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1850/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0271 - mae: 0.0271 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1851/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1852/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1853/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1854/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1855/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1856/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1857/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1858/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1859/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1860/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1861/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1862/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1863/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1864/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1865/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1866/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1867/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1868/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1869/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1870/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1871/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1872/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1873/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1874/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1875/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1876/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1877/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1878/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1879/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1880/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1881/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1882/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1883/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1884/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1885/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1886/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1887/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1888/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1889/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1890/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1891/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1892/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1893/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1894/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1895/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1896/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1897/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1898/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1899/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1900/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1901/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1902/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1903/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1904/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1905/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1906/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1907/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1908/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1909/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1910/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1911/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1912/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1913/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1914/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1915/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1916/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1917/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1918/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1919/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1920/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1921/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1922/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1923/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1924/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1925/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1926/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1927/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1928/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1929/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1930/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1931/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1932/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1933/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1934/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1935/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1936/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1937/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1938/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1939/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1940/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1941/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1942/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1943/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1944/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1945/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1946/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1947/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1948/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1949/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1950/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1951/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1952/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1953/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1954/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1955/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1956/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1957/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0259 - mae: 0.0259 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1958/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1959/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1960/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1961/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1962/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1963/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1964/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1965/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1966/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1967/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1968/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1969/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1970/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1971/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1972/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1973/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1974/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1975/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1976/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1977/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1978/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1979/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1980/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1981/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1982/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1983/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1984/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1985/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1986/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1987/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1988/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1989/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1990/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1991/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1992/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1993/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1994/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1995/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1996/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1997/2100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1998/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1999/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2000/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2001/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2002/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2003/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2004/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2005/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2006/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 2007/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2008/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2009/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2010/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2011/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2012/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 2013/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2014/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 2015/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 2016/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 2017/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 2018/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 2019/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 2020/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 2021/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2022/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2023/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 2024/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2025/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2026/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 2027/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2028/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 2029/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2030/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2031/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 2032/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2033/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 2034/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2035/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2036/2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2037/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2038/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2039/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 2040/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2041/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2042/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2043/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2044/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2045/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 2046/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2047/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2048/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2049/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 2050/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 2051/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2052/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2053/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2054/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 2055/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 2056/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2057/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2058/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2059/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2060/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 2061/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2062/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2063/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2064/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2065/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2066/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2067/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2068/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 2069/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2070/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 2071/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2072/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2073/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 2074/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0258 - mae: 0.0258 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2075/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2076/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2077/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2078/2100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2079/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2080/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2081/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0272 - mae: 0.0272 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2082/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 2083/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3614 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 2084/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2085/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2086/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2087/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2088/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2089/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2090/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2091/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2092/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 2093/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 2094/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2095/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 2096/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3614 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 2097/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2098/2100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3614 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3614 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 2099/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 2100/2100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 44.3614 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3614 - val_mse: 0.1589 - val_mae: 0.1589\n"
     ]
    }
   ],
   "source": [
    "t = Trainer(testnetBernoulli,\n",
    "                    NLL,\n",
    "                    (train,test),\n",
    "                    batch_size = 1,\n",
    "                    optimizer=optimizer,\n",
    "                    dimension = dimension,\n",
    "                    channels = channels,\n",
    "                    metrics = [\"mse\",\"mae\"])\n",
    "\n",
    "print(\"len train,val\",len(train),len(test))\n",
    "t.fit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXRc53nf8e8zGwbLACBBcBF3UpQtSrJlBpY3xbIdxZaU1mpP7VpqHNuyEh73RIlzbPdUOenx2p7aabN4UesqrRwviVQ1thvFla0krhM3drRQMrXSlCiJEiFSIrhgB2Z9+sd7AQyHAwKQMAA59/c5B2dm7r0z97kv7txn3vve+77m7oiISHwlljsAERFZXkoEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEIDIHM9tiZm5mqXks+yEz+4eliEtksSgRSFMxs4NmVjCzVTXT90YH8y3LE9kpCeWhmumropgPVk273Mx+amZDZnbCzH5iZq+P5n3IzMpmNlrzd94Sb5I0CSUCaUbPAtdPvTCzS4DW5QvnNO1mdnHV639FiBkAM+sEvgd8GVgJrAc+A+Sr3vOP7t5R83d4CWKXJqREIM3om8AHql5/EPhG9QJm1mVm3zCzATN7zsz+nZklonlJM/vPZnbMzJ4BfqXOe/+HmR0xsxfM7N+bWXKB8X2w6vUHauK7AMDdb3f3srtPuPtfu/sjC1iHyLwpEUgzuhfoNLMLowP0+4Bv1SzzZaAL2AZcQTgY3xDN+w3gnwCvA/qA99S89+tACTg/WuadwK8vIL5vAddFCedCIAfcVzX/SaBsZl83s6vNbMUCPltkwZQIpFlN1Qp+Gfg58MLUjKrk8LvuPuLuB4E/AH4tWuRfAn/s7ofc/QTwH6veuwa4Gvgddx9z96PAHwHXLSC2fmA/cCV1aivuPgxcDjjwJ8CAmd0VrXvKG81ssOrv6QWsX+QUc14FIXKO+ibwY2ArNQdaYBWQAZ6rmvYc4Vw8wHnAoZp5UzYDaeCImU1NS9QsPx/fAD4EvBl4K7Cjeqa774vmY2avJtQi/piZto973f3yBa5TpC7VCKQpuftzhAbYa4Dv1Mw+BhQJB/Upm5ipNRwBNtbMm3KI0Gi7yt27o79Od79ogSF+m9D28EwU65m25efAnwIXn2k5kZdLiUCa2Y3AO9x9rHqiu5eBO4H/YGY5M9sMfIyZdoQ7gd82sw3R+fmbq957BPhr4A/MrNPMEma23cyuWEhgUUzvoE7bgpm92sw+bmYbotcbCTWBexeyDpH5UiKQpuXuT7v7nllm/xYwBjwD/APw58Bt0bw/Ae4BHgYe4vQaxQcIp5aeAE4CfwGsexnx7XH3euf2R4A3APeZ2RghATwGfLxqmTfVuY/g9QuNQQTANDCNiEi8qUYgIhJzSgQiIjGnRCAiEnNKBCIiMXfO3VC2atUq37Jly3KHISJyTnnwwQePuXtvvXkNSwRmdhuhv5aj7n7ajTAWbsv8IuGGn3HgQ+7+UO1ytbZs2cKePbNdESgiIvWY2aw3Ljby1NCfAledYf7VhNvqdwC7gf/awFhERGQWDUsE7v5j4MQZFrkW+IYH9wLdZrbgm3JEROSVWc7G4vWc2lFXPzOdfomIyBJZzsZiqzOt7m3OZrabcPqITZs2nTa/WCzS39/P5OTkogZ4Nstms2zYsIF0Or3coYjIOW45E0E/p/bwuAGoO9Seu98K3ArQ19d3WrLo7+8nl8uxZcsWqroGblruzvHjx+nv72fr1q3LHY6InOOW89TQXcAHLHgjMBT17Lhgk5OT9PT0xCIJAJgZPT09saoBiUjjNPLy0duBtwGrzKwf+BRhQA/c/avA3YRLRw8QLh+9of4nzXt9r+Tt55y4ba+INE7DEoG7Xz/HfAd+s1Hrr5UvljkxXmBtZ1YHURGRKrHpYmJossjASJ7RfGnRP/v48eNceumlXHrppaxdu5b169dPvy4UCvP6jBtuuIH9+/cvemwiInM557qYeLlWtbcwMJxnaLxILru4V9r09PSwd+9eAD796U/T0dHBJz7xiVOWcXfcnUSifu792te+tqgxiYjMV2xqBImEkWtNMzxZYqkG4zlw4AAXX3wxH/nIR9i1axdHjhxh9+7d9PX1cdFFF/HZz352etnLL7+cvXv3UiqV6O7u5uabb+a1r30tb3rTmzh69OiSxCsi8dR0NYLP/NXjPHF4uO68UsXJF8u0ZpIkFtBOsPO8Tj71Txc6NnnwxBNP8LWvfY2vfvWrAHz+859n5cqVlEol3v72t/Oe97yHnTt3nvKeoaEhrrjiCj7/+c/zsY99jNtuu42bb7653seLiLxisakRACQT4eBfqizd8Jzbt2/n9a+fGUr29ttvZ9euXezatYt9+/bxxBNPnPae1tZWrr76agB+4Rd+gYMHDy5VuCISQ01XI5jrl/vTA6OUK84Fa3JLEk97e/v086eeeoovfvGL3H///XR3d/P+97+/7r0AmUxm+nkymaRUWvwGbhGRKbGqEQB0ZlNMFssUSpUlX/fw8DC5XI7Ozk6OHDnCPffcs+QxiIjUaroawVxy2TRHhiYZmSzS09GypOvetWsXO3fu5OKLL2bbtm285S1vWdL1i4jUY0t1Bc1i6evr89qBafbt28eFF144r/e7O/tfGiGbSrJlVfvcbziLLWS7RSTezOxBd++rNy92p4bMjFw2zWi+ROUcS4IiIo0Qu0QA0J5JUvFwKamISNzFMhG0ZZIAjBeUCEREYpkI0skEqURCiUBEhJgmAjOjLZNUIhARIaaJAKA1kyRfKlOuLP39BCIiZ5PYJoKpdoKJRagVLEY31AC33XYbL7744iuOR0RkIWJ3Q9mU1nSUCIoVOrKv7LPm0w31fNx2223s2rWLtWvXvrKAREQWILaJIBU1GDf6EtKvf/3r3HLLLRQKBd785jfzla98hUqlwg033MDevXtxd3bv3s2aNWvYu3cv73vf+2htbeX+++8/pc8hEZFGab5E8P2b4cVH57Xo1qkkENUOZrX2Erj68wsO5bHHHuO73/0uP/3pT0mlUuzevZs77riD7du3c+zYMR59NMQ5ODhId3c3X/7yl/nKV77CpZdeuuB1iYi8XM2XCBYgYaFLascxFn8c47/927/lgQceoK8v3NU9MTHBxo0bede73sX+/fv56Ec/yjXXXMM73/nORV+3iMh8NV8iWMAv99HRPC8MTnDh2k7SqcVvN3d3PvzhD/O5z33utHmPPPII3//+9/nSl77Et7/9bW699dZFX7+IyHzE9qohgJbo4J8vNaad4Morr+TOO+/k2LFjQLi66Pnnn2dgYAB3573vfS+f+cxneOihhwDI5XKMjIw0JBYRkdk0X41gNoUxyA9Dbt30pEwqtA3kSxU6GrDKSy65hE996lNceeWVVCoV0uk0X/3qV0kmk9x44424O2bGF77wBQBuuOEGfv3Xf12NxSKypOLTDfXoAAz3w+qdkArjELg7jx8eZmV7hvO6WxsVcsOoG2oRmS91Qw2QaQuPpZmhIc2MTCqxLKOViYicLeKTCKJaAMVTxwhuSSXIKxGISIw1TSKY8xRXIhX+SqcmgkwqQaFcmfv9Z5lzLV4ROXs1RSLIZrMcP3587oNjKnt6IkgmcHdKlXPnwOruHD9+nGz2FfaNISJCk1w1tGHDBvr7+xkYGDjzghMnoTAKA2WwcAPZZLHMsdECfrKFTAPuJWiUbDbLhg0bljsMEWkCTZEI0uk0W7dunXvBh74JP7gJfush6NkOwFMvjfDP//zHfPG6S7n2kvUNjlRE5Oxz7vwEXgyrd4bHo09MT1q/Ilw2+sLgxHJEJCKy7GKWCF4dHo/um57UlknR056h/6QSgYjEU7wSQaYdujbCsadOmbx+RSsvKBGISEw1NBGY2VVmtt/MDpjZzXXmbzKzH5nZz8zsETO7ppHxAKFt4PipiWB1roWjI/mGr1pE5GzUsERgZkngFuBqYCdwvZntrFns3wF3uvvrgOuA/9KoeKb17IDjT0PVpaa9uSwDSgQiElONrBFcBhxw92fcvQDcAVxbs4wDndHzLuBwA+MJel8VOp8bfH5mUq6F42N5SmXdYSwi8dPIRLAeOFT1uj+aVu3TwPvNrB+4G/iteh9kZrvNbI+Z7ZnzXoG5rItG/6pqMO7NteAOJ8bmP9C8iEizaGQiqDfkV+3tu9cDf+ruG4BrgG+a2Wkxufut7t7n7n29vb2vLKoVm8Pj4HPTk1bnQj9EaicQkThqZCLoBzZWvd7A6ad+bgTuBHD3fwSywKoGxgTtvZBug5MziaA3SgRqJxCROGpkIngA2GFmW80sQ2gMvqtmmeeBXwIwswsJieAVnvuZgxms2AInn52e1NsxVSOYnOVNIiLNq2GJwN1LwE3APcA+wtVBj5vZZ83s3dFiHwd+w8weBm4HPuRL0a1mz3Y4fmD6pWoEIhJnDe1ryN3vJjQCV0/7ZNXzJ4C3NDKGunrOh/0/gHIJkimy6SSd2ZTaCEQkluJ1Z/GUnh1QKZ7SYNyba1GNQERiKZ6JYOW28Hiiqp1AiUBEYiqeiaA7uphpaOY2h1UdLRzXfQQiEkPxTAQda8GSpyWCY6oRiEgMxTMRJFPQuR4GqxNBhpF8iclieRkDExFZevFMBABdG06rEQA6PSQisRPvRDD8wvTLFe0ZAE4qEYhIzMQ4EayH4SNQCT2OdremARiaKC5nVCIiSy6+iaBzfbiXYOwoAN1toUYwOK5EICLxEu9EANOnh7qiGsHghE4NiUi8xDgRnBceh0Ii6G7TqSERiaf4JoKuDeFxOPSMnU0nyaQSDOnUkIjETHwTQVsPJFtguH96UndrWjUCEYmd+CYCs3B6aHhmrJzutrQai0UkduKbCCC6qWzmXoKu1rQai0UkduKdCGpqBF2tGYYmSssYkIjI0lMiGDkM0aBo3W1phsZVIxCReIl3ImhfDZUSTA4C4dSQGotFJG5inghWhcexY0C4amisUKZQqixjUCIiS0uJAKYTQZduKhORGIp5IugNj2MDwEw3E0oEIhIn8U4EbVM1gpAIpjqeG9IlpCISIzFPBD3hcfw4oBqBiMRTvBNBKgPZrpkawVQPpLq7WERiJN6JAEI7wfSpISUCEYkfJYL23umrhnJZnRoSkfhRImjrmU4EyYTRmU0pEYhIrCgRVJ0agnAvgRKBiMSJEkF7L0ycgEoZgO7WDIPqb0hEYkSJoH0VeAUmTgLqb0hE4keJoP3Um8o6WlKM5tUVtYjEhxLBdDcTocG4I5tidFKJQETiQ4mgppuJXDbFiGoEIhIjDU0EZnaVme03swNmdvMsy/xLM3vCzB43sz9vZDx11dQIctGpIY8GqxERaXapRn2wmSWBW4BfBvqBB8zsLnd/omqZHcDvAm9x95NmtrpR8cyqbSVgMD5zasgdxgtl2lsaVjwiImeNRtYILgMOuPsz7l4A7gCurVnmN4Bb3P0kgLsfbWA89SWSIRlMNxaHu4tH1E4gIjHRyESwHjhU9bo/mlbtAuACM/uJmd1rZlfV+yAz221me8xsz8DAQL1FXpmqm8o6sqEWMJrXJaQiEg+NTARWZ1rtifcUsAN4G3A98N/NrPu0N7nf6u597t7X29u76IHStgrGQlfUueh0kGoEIhIXjUwE/cDGqtcbgMN1lvlLdy+6+7PAfkJiWFrtq065agjQvQQiEhuNTAQPADvMbKuZZYDrgLtqlvnfwNsBzGwV4VTRMw2Mqb723lMaiwHdSyAisdGwRODuJeAm4B5gH3Cnuz9uZp81s3dHi90DHDezJ4AfAf/G3Y83KqZZta8KXUyUS3RMnRpSjUBEYqKh10e6+93A3TXTPln13IGPRX/Lp3VFeJwcItfSCaiNQETiQ3cWA2Sj9umJk7S3JAGdGhKR+FAigKoawSCpZILWdFKXj4pIbCgRALTO1AggXDmkq4ZEJC6UCGCmRjAxCIQrh9RGICJxoUQAVYkgqhFoTAIRiRElAoBsV3icVI1AROJHiQAgmYZMbrpG0NGiwWlEJD7OmAjM7P1Vz99SM++mRgW1LFq7qxqL0zo1JCKxMVeNoPpGry/XzPvwIseyvKoSQUdLipFJXT4qIvEwVyKwWZ7Xe31uy3bD5BAwc/moRikTkTiYKxH4LM/rvT63ZbtmLh9tSVGJRikTEWl2c/U19Goze4Tw63979Jzo9baGRrbUWmdqBFNDVI7lSxquUkSa3lxHuQuXJIqzQbZ7+vLRqTEJRvIlln4QZRGRpXXGRODuz1W/NrMe4K3A8+7+YCMDW3LZbiiOQ6lAe2amRiAi0uzmunz0e2Z2cfR8HfAY4Wqhb5rZ7yxBfEtnqr+hyaHp00G6hFRE4mCuxuKt7v5Y9PwG4G/c/Z8Cb6DZLh+turt46tTQWF6NxSLS/OZKBNUX0/8S0SAz7j4CVBoV1LLI1qsR6F4CEWl+czUWHzKz3yIMMr8L+AGAmbUC6QbHtrSmu6IepL0rGpxGNQIRiYG5agQ3AhcBHwLe5+6D0fQ3Al9rYFxLr/rUUEvIcWosFpE4mOuqoaPAR+pM/xFhsPnmMX1qaJBsOkHCNFyliMTDGROBmd11pvnu/u7FDWcZTdUIJgYxM9o1JoGIxMRcbQRvAg4BtwP30Wz9C1VLZyGVnelvqCWlU0MiEgtzJYK1wC8D1wP/Cvg/wO3u/nijA1sW2a7pu4tVIxCRuDhjY7G7l939B+7+QUID8QHg76IriZpP9tT+hpQIRCQO5uxRzcxagF8h1Aq2AF8CvtPYsJZJa/d0D6S5rE4NiUg8zNVY/HXgYuD7wGeq7jJuTtkuGD0KQHsmxUvDk8sckIhI481VI/g1YAy4APhts+m2YgPc3TsbGNvSy3bDsSeBcGpIXUyISBzMdR9BvAa3rxqcZmqUMhGRZhevA/1cWrshPwyVCu0tSQ1XKSKxoERQLdsFXoHCCO0tKcoVJ19qrr71RERqKRFUq+qBNKcxCUQkJpQIqlX3QDqVCNTfkIg0OSWCatM9kGqUMhGJj4YmAjO7ysz2m9kBM7v5DMu9x8zczPoaGc+cqnog7WjRuMUiEg8NSwRmlgRuAa4GdgLXm9nOOsvlgN8mdGq3vKp6IO1QjUBEYqKRNYLLgAPu/oy7F4A7gGvrLPc54PeB5b+NVwPYi0gMNTIRrCd0YT2lP5o2zcxeB2x09++d6YPMbLeZ7TGzPQMDA4sf6ZRMDrCaU0O6u1hEmlsjE0G9sQum784yswTwR8DH5/ogd7/V3fvcva+3t3cRQ6yRSERdUQ/RkdUA9iISD41MBP3AxqrXG4DDVa9zhA7t/s7MDhK6ub5r2RuMox5I29JJzDSAvYg0v0YmggeAHWa21cwywHXA9NCX7j7k7qvcfYu7bwHuBd7t7nsaGNPcohpBImF0ZFKMTKpGICLNrWGJwN1LwE3APcA+4E53f9zMPmtmZ+9Yx9nu6VHKOrIp3VAmIk1vzoFpXgl3vxu4u2baJ2dZ9m2NjGXesl0w8CIQeiAdUSIQkSanO4trtc4MV5nLphlRY7GINDklglpVA9irRiAicaBEUCvbDaVJKE6GGoESgYg0OSWCWlV3F4cagU4NiUhzUyKoVdXxXK4lxbBqBCLS5JQIamVPrREUShXyJd1UJiLNS4mgVlUPpLlsGkDtBCLS1JQIarWuCI8TJ8llNUqZiDQ/JYJabSvD48QJ1QhEJBaUCGplu8ASMH5iukagK4dEpJkpEdRKJEOD8fjx6USgK4dEpJkpEdTT1hNODbVMnRpSjUBEmpcSQT1tK0+pEaiNQESamRJBPW09MH5iepQyJQIRaWZKBPW0rYTxE6STCVrTSZ0aEpGmpkRQT2s4NYQ7uWyK0bxqBCLSvJQI6mnrgXIeCmPqilpEmp4SQT01N5UN69SQiDQxJYJ62nrCY3TlkGoEItLMlAjqmU4EJzQmgYg0PSWCelqjU0Pj4aYy1QhEpJkpEdSjU0MiEiNKBPW0dkcdzx0jl00zUSxTLFeWOyoRkYZQIqgnkYT21TByZLqbiTHdSyAiTUqJYDad62D4iPobEpGmp0Qwm9x5p9QIdC+BiDQrJYLZdK6D4cMapUxEmp4SwWxy62BykM5USABKBCLSrJQIZtN5HgDd5eOABqcRkealRDCb3LrwUBgAVCMQkealRDCbKBG0548CqhGISPNSIphNZ0gE6bEXySQTjOg+AhFpUg1NBGZ2lZntN7MDZnZznfkfM7MnzOwRM/uhmW1uZDwL0tIJmRwM9ZNNJ8gXdWexiDSnhiUCM0sCtwBXAzuB681sZ81iPwP63P01wF8Av9+oeBbMDLo3weDzZFJJ8iUlAhFpTo2sEVwGHHD3Z9y9ANwBXFu9gLv/yN3Ho5f3AhsaGM/CrdgMg8/TkkqQL5WXOxoRkYZoZCJYDxyqet0fTZvNjcD3GxjPwnVvhpPP0ppyCqoRiEiTSjXws63ONK+7oNn7gT7gilnm7wZ2A2zatGmx4pvbutdCcZyt2RfJl7qWbr0iIkuokTWCfmBj1esNwOHahczsSuD3gHe7e77eB7n7re7e5+59vb29DQm2rtWvBmCbvaAagYg0rUYmggeAHWa21cwywHXAXdULmNnrgP9GSAJHGxjLy7PqAgC2VZ5XG4GINK2GJQJ3LwE3AfcA+4A73f1xM/usmb07Wuw/AR3A/zKzvWZ21ywftzwy7bDqAi4oPamrhkSkaTWyjQB3vxu4u2baJ6ueX9nI9S+KjZex4+G/pFBUjUBEmpPuLJ7LxjfQURmht3Bo7mVFRM5BSgRz2fgGAF5dfGKZAxERaYyGnhpqCj07GEt2cmFp3+nz8qNw/Cno3wNHn4CHvgFv+Ai4w7EnIT8Moy/ByYOw5RehrQdefATWvgYKY9C1AQ4/BEceDp+3+XLA4dD9IQEdexJW7QjLFSfC5z3zd2HZta8Jn7X9HfD0/515rLb1Cnj278PzVa+C9bvgpcfgxUch2RLe82TNrRuWAK/A+b8MqRYYfD50yZ3pgJEj0LYSKhU4+njYLgjbVhwPHfUduh/GjsK2t0O6Laxr6Plwl3ZhDMaPw6Y3weQwFEbD9q59Dfz8e+GzVmyFk8+G512bYOXWEAcGrStCWY0fh9xaGOqH/AikslApgiWhOAZdG2EoqsF1rAnxH3kENrweDv8MVl8I3RvDNj18e1jnpjeGz27rCe9/8dGwHT3nQ6UEhXF46dHwmeteG5Zd+5pQBvnh8Nn9D0Dn+hBHuQDJNJQmYWxgpnxXbocTz0DH6rBvVKve9imJNPS+Kvw99m1Yc0n0/2iD/T+A0gSsuRiGXwhlev6V8NQ9Yf85eTAsm1sHh+6DDZeFMk+1QLo1xDnyIhy6N5RF68rwv+rcAOtfB4cegGwXrNgStrf3AjjxbNgPOs8L+8aUVDas+7mfhDhy60IbW7oVJk6EfWHg52HZDZeFeZYI/7/CWNif0u1w3uugtTvsD5kcFEZO/95N6Vwf3rv1F6FSDrE+fHuYt+1tkEjBCw+F705pYmZfHT4ceg5YfWHY5ko57FMDP58pf0vAlsvh2R9HZbMilNvxA2F+Ww+s3Ba+o5NDYV2VqD+yNZeEfSXdFr4XU3ZeG8pv9U545I5Tt2XHO8N3u1wI+1KmAyZOQjITyv7V14R1vO79YdsWmbnXvbT/rNXX1+d79uxZ0nXu/8OrSQ0/x/ZPPQ4/+xb85IvhCzVy5BV+sjHLrRWn6t4Udip3OLa//jItneGAdCYda04/+MwaWgLaVoWDYbodWjpCgmhbFbZ9qOpU2dSXoHrHt2TYmfNDZ15Pui1s39RB4kzb1rEWRl+cX/z1ZLthcjB63hXWPfU/bF8dthULB5jx4+HgkcyE+eXCHB8+z//ly9W9GQafm3nd0jVTtsnMTHytK8OB95TQouQ+9X/KdIQ/fPb9ob13JoFlOqKkPYdU68wBt1YiHZL1lHQ7tOTC/mIWDqYh2GjdC7iIMJMLPwCy3TPb3tYTDqRec5FHbRwdayGRDOuv3cb5bvd8dW2C8WNhf67dj6sTST1tq0J5vf334DXvfVmrN7MH3b2v3jzVCObhcO4S3j78U/hM96kzdn0g/BKyRPjls3Jb+BXu5XBgMQsHb7Nw0Kl+Xa1SmZlWO6+eqc+o91lTiX1qeu3rs1X1ttTbrlfyeYupEZ/bqFgXw5liW4q46+3rc633lc6fTzyNWn6ZKBHMw76117Kt/7tstqNw6a/CL34cera/vA+rt1MkFthUc6akUTvtHNgJgVPjXIyYG7Xdjfjcs/l/dKbYliLuevv6XOt9pfMX871n8/+2ihLBPJTaVnNF/o858B+uJpVU+7qINBcd1eahJRWKqVDWTWUi0nyUCOZhKhFocBoRaUZKBPOQSSUB1QhEpDkpEcxDayYU05jGLRaRJqREMA+d2TQAI5NKBCLSfJQI5qGzVYlARJqXEsE8TNUIhieLcywpInLuUSKYh1w23G4xPKFEICLNR4lgHnRqSESamRLBPLRnkiRMp4ZEpDkpEcyDmdHdluHE2Fw9UIqInHuUCOZpda6FoyP55Q5DRGTRKRHM0+rOLEeHJ5c7DBGRRadEME9rci28NKwagYg0HyWCeVrblWVgNE9R/Q2JSJNRIpinbb3tlCvOwWNjyx2KiMiiUiKYpx2rcwA8+dIijmEqInIWUCKYp+29HZjBky+NLHcoIiKLSolgnlozSS5YnWPPcyeWOxQRkUWlRLAAb71gFQ88e5JRjUsgIk1EiWABrr5kHYVyhW/d+9xyhyIismiUCBZg16YVvO1VvfyXHx3g0Inx5Q5HRGRRpJY7gHPNJ//JTq695Sf8ypf+H+/t28ivvGYdq3MtrOtqJWFhGbPwxN1xD9MSCaNUrpBMGGaGu1MsO4VyhWwqQaniJKc+AEhFy9Uzli/RlkmeMt/dMTMqFWeyVKYlFTrKy5cqtKQSDE+UyKQSpJNGwoyxQolUIkE2nSBfqpBOht8Ek8UyxXKFTBRTsVShNZPEMFLJsL6pz3QnWleCYtlJmlEd8nihTHtLkmLZMaDiTqFUIZtOkkwYk8UyhpFOGS2pJO5OqeKnrKPiTjaVZLxYJp20sM5imWTCSCcTTBbLpJMJsirz7McAAAtfSURBVOkk5YqTShgT0XwzopiMwfECmVSCVCJBKmlUov9NxZ1K9OiVqddhWntLGKu6XHFaUknSSaNcccaLZToyKYqVCpPFcF9J9f++LR3eN1YokYjKJGFGqeK0pZOMTJboyKZIGLP+j6cUyxUmi2Vy2TSlcoVSZWqfSTJZKpNNJSlVKqQSCfKlMvlShRVtGUqVCu4z+1GxXIliqFAshzJuSSUwY7ocwnaE/aNQrlAoVWjLJClVnFK5QksqSSpp5EsV8sVyKHN3WlIJEhbKNF+qUC47qaSRSYV9qz2TYrxQolKBVNKm93WD6X2+UK6QSYZ4WlLhfzmaL9GaDttXLDkt6bA/ZJKJ6fHD08mwH5pBqeyYhW3Olyrko/jdwXEMo+zOWL7EirYMhXIF9xCLO7Smk+RLFRIJyCQTTBYrOE654tPrmdqvpvbREINRiJ5nou/FlKm4pr47hVL4X7WkEjgwmi9Nb3epEsrSgHJ0fEhFsU19T7PRvrXYzKujPgf09fX5nj17ljWGA0dH+MT/eoS9hwZPmT51MEglE9M7Rq2EgQPzKfZkwsKfhceEhS9M9cHHbOaglkyEA5WcW6YShcF04piaNl4oA+EgNVEsL2+gS6T6QC+n+tw/u5hfe+Pml/VeM3vQ3fvqzVON4GU4f3WO//2bb+Ho8CQ/fuoYf/XwYS5c1xn9OjWK5fBrxoCT4wVSiQS5bIpMKvxyLZYrDI4Xuf/ZE7S1JOnbvIL+kxPTyaO7LcOazha629KUo1+ppbJHv7jKfO/hI/zqGzeTjn7ZTv3qLVUqJBMJnh4Ypas1TSphtKaTOLD3+UG2r+4gYdCRTfGtf3yO129dyWs3dNN/cgIz6GgJu8P3HjnMirYMTx0dZVtvOwC5lhQbVrRRKFc4cHSUt+5YxfMnxjk+VuCi87oYmSxyXncrx0by9A9OsL23naPDedZ0ZRmaKNKeSbLn4Eku27qS+w+eoKMlxchkiRcGJ9je28EVF/TiOM8dG2dzTxs/e36QDStbGRovcvH6Lv7svue5dGMXxbLz4HOhwf7KC9fww5+/xFUXrZ0ufzMYy5dZ2Z4J/wODyUKZ+549wYYVbVy6sQsICTT8+uWUX+0JC7W3gZE8T700Sks6/Npd25WlXHGOjeT5zs9e4Ka3n8+J8QLHRvI89Pwgx0bzXLy+k1LZ+cUdqzg5XuTFoUkq7nRm06zsyFAuO7lsivsPnuCtO3pJRTUcj2ogzkzthOhxsljh8OAE23rbGZooMlGscHw0T1smRUs6EWpLhRKbe9oZHC9QKFVY05WlUKrQ1RpqEYVyqIlV3PnJgWMcPD7G2161mvXdrQAMjOQZmiiSShoXrusknQi/5r/zsxdoSSVZ29nCg8+dZMeaHG/d0UtrJsHxsQI/e26Q/S+NcNF5nezatILRfIm/f3KAl4YnWdOZ5YI1Hfzo5wN8+PKt/PjJAZwwyNPeQ4O841Wr6WoN5VKpOEMTRbLpJL25FkbzJYYmiuw7MszOdZ0MThT5P48c4T2/sIH7nz3Buy5aw+B4kYHRPK9akwODfLFC/8lxXruhm9FCiWMjBQZG87x+8woe7h+kLZMiXyozEP2/dm3q5sJ1nWxa2cZovsTR4Txru7I8c2yMF06O8/qtK/mrvYf5tTdtYWAkz9MDo1yyvotU0jCMF4cnODI0yfruVnpzLQyOF1nVkcEdfvr0cdpbUrg723rbefbYOBtWtPLoC0NcfF4nyUSCZCLUZvpPTrCiLU13W4ZDJ8dZ1dFCOmkcHy3w4vAkuWyartYUK9tbuGvvC7zj1asbckxTjUBEJAbOVCNoaGOxmV1lZvvN7ICZ3VxnfouZ/c9o/n1mtqWR8YiIyOkalgjMLAncAlwN7ASuN7OdNYvdCJx09/OBPwK+0Kh4RESkvkbWCC4DDrj7M+5eAO4Arq1Z5lrg69HzvwB+yea6jEJERBZVIxPBeuBQ1ev+aFrdZdy9BAwBPbUfZGa7zWyPme0ZGBhoULgiIvHUyERQ75d9bcv0fJbB3W919z537+vt7V2U4EREJGhkIugHNla93gAcnm0ZM0sBXYB6dRMRWUKNTAQPADvMbKuZZYDrgLtqlrkL+GD0/D3A//Vz7XpWEZFzXMNuKHP3kpndBNwDJIHb3P1xM/sssMfd7wL+B/BNMztAqAlc16h4RESkvnPuhjIzGwBebvefq4BjixhOM1IZnZnKZ24qozNbrvLZ7O51G1nPuUTwSpjZntnurJNAZXRmKp+5qYzO7GwsH3VDLSISc0oEIiIxF7dEcOtyB3AOUBmdmcpnbiqjMzvryidWbQQiInK6uNUIRESkhhKBiEjMxSYRzDU2QlyY2UEze9TM9prZnmjaSjP7GzN7KnpcEU03M/tSVGaPmNmu5Y2+MczsNjM7amaPVU1bcJmY2Qej5Z8ysw/WW9e5aJby+bSZvRDtR3vN7Jqqeb8blc9+M3tX1fSm/A6a2UYz+5GZ7TOzx83so9H0c2cfCgOsN/cf4c7mp4FtQAZ4GNi53HEtU1kcBFbVTPt94Obo+c3AF6Ln1wDfJ3QO+EbgvuWOv0Fl8lZgF/DYyy0TYCXwTPS4Inq+Yrm3rYHl82ngE3WW3Rl9v1qArdH3LtnM30FgHbArep4DnozK4ZzZh+JSI5jP2AhxVj0uxNeBf1Y1/Rse3At0m9m65Qiwkdz9x5ze2eFCy+RdwN+4+wl3Pwn8DXBV46NvvFnKZzbXAne4e97dnwUOEL5/TfsddPcj7v5Q9HwE2EfoYv+c2YfikgjmMzZCXDjw12b2oJntjqatcfcjEHZqYGqE7DiX20LLJI5ldVN0auO2qdMexLx8ouF2Xwfcxzm0D8UlEcxr3IOYeIu77yIMIfqbZvbWMyyrcjvdbGUSt7L6r8B24FLgCPAH0fTYlo+ZdQDfBn7H3YfPtGidactaRnFJBPMZGyEW3P1w9HgU+C6hyv7S1Cmf6PFotHicy22hZRKrsnL3l9y97O4V4E8I+xHEtHzMLE1IAn/m7t+JJp8z+1BcEsF8xkZoembWbma5qefAO4HHOHVciA8Cfxk9vwv4QHSVwxuBoamqbgwstEzuAd5pZiui0yTvjKY1pZq2on9O2I8glM91ZtZiZluBHcD9NPF30MyM0KX+Pnf/w6pZ584+tNwt7kv1R2ipf5Jw5cLvLXc8y1QG2whXazwMPD5VDoRxon8IPBU9roymG3BLVGaPAn3LvQ0NKpfbCac3ioRfZTe+nDIBPkxoHD0A3LDc29Xg8vlmtP2PEA5s66qW/72ofPYDV1dNb8rvIHA54RTOI8De6O+ac2kfUhcTIiIxF5dTQyIiMgslAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQKRGmZWrupVc+9i9pRpZluqe/EUORukljsAkbPQhLtfutxBiCwV1QhE5snCWA5fMLP7o7/zo+mbzeyHUQdsPzSzTdH0NWb2XTN7OPp7c/RRSTP7k6jv+r82s9Zl2ygRlAhE6mmtOTX0vqp5w+5+GfAV4I+jaV8hdCv8GuDPgC9F078E/L27v5bQn//j0fQdwC3ufhEwCPyLBm+PyBnpzmKRGmY26u4ddaYfBN7h7s9EnYy96O49ZnaM0MVCMZp+xN1XmdkAsMHd81WfsYXQ5/yO6PW/BdLu/u8bv2Ui9alGILIwPsvz2ZapJ1/1vIza6mSZKRGILMz7qh7/MXr+U0JvmgC/CvxD9PyHwL8GMLOkmXUuVZAiC6FfIiKnazWzvVWvf+DuU5eQtpjZfYQfUddH034buM3M/g0wANwQTf8ocKuZ3Uj45f+vCb14ipxV1EYgMk9RG0Gfux9b7lhEFpNODYmIxJxqBCIiMacagYhIzCkRiIjEnBKBiEjMKRGIiMScEoGISMz9f3QUDegb6Zg5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "history = t.history\n",
    "def plotHistory():\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history['mse'])\n",
    "    plt.plot(history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "plotHistory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
